{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "hw3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WLMK2jD8-Vr"
      },
      "source": [
        "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
        "## Домашнее задание №3 - Дерево решений\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K69Xnm38-Wc"
      },
      "source": [
        "**Общая информация**\n",
        "\n",
        "**Срок сдачи:** 3 мая 2021, 08:30   \n",
        "**Штраф за опоздание:** -2 балла после 08:30 03 мая, -4 балла после 08:30 10 мая, -6 баллов после 08:30 17 мая, -8 баллов после 08:30 24 мая.\n",
        "\n",
        "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
        "[ML0221, Задание 3] Фамилия Имя. \n",
        "\n",
        "\n",
        "Используйте данный Ipython Notebook при оформлении домашнего задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzFnTkin8-Wh"
      },
      "source": [
        "##  Реализуем дерево решений (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obl6oJtC8-Wi"
      },
      "source": [
        "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
        "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс DecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qOMcvA18-Wj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from collections import defaultdict\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUW2BPSf8-Wl"
      },
      "source": [
        "class MyDecisionTreeClassifier:\n",
        "    NON_LEAF_TYPE = 0\n",
        "    LEAF_TYPE = 1\n",
        "\n",
        "    def __init__(self, min_samples_split=2, max_depth=3, criterion='gini'):\n",
        "        \"\"\"\n",
        "        criterion -- критерий расщепления. необходимо релизовать три:\n",
        "        Ошибка классификации, Индекс Джини, Энтропийный критерий\n",
        "        max_depth -- максимальная глубина дерева\n",
        "        min_samples_split -- минимальное число объектов в листе, чтобы сделать новый сплит\n",
        "        \"\"\"\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.num_class = -1\n",
        "        # Для последнего задания\n",
        "        self.feature_importances_ = None\n",
        "        self.criterion = criterion\n",
        "        # Структура, которая описывает дерево\n",
        "        # Представляет словарь, где для  node_id (айдишник узла дерева) храним\n",
        "        # (тип_узла, айдишник признака сплита, порог сплита) если тип NON_LEAF_TYPE\n",
        "        # (тип_узла, предсказание класса, вероятность класса) если тип LEAF_TYPE\n",
        "        # Подразумевается, что у каждого node_id в дереве слева \n",
        "        # узел с айди 2 * node_id + 1, а справа 2 * node_id + 2\n",
        "        self.tree = dict()\n",
        "        self.feature_importances_ = defaultdict(float)\n",
        "        \n",
        "        if criterion == 'entropy':\n",
        "            self.impurity = self.__entropy\n",
        "        elif criterion == 'gini':\n",
        "            self.impurity = self.__gini\n",
        "        elif criterion == 'misclass':\n",
        "            self.impurity = self.__misclass\n",
        "\n",
        "    def __div_samples(self, x, y, feature_id, threshold):\n",
        "        \"\"\"\n",
        "        Разделяет объекты на 2 множества\n",
        "        x -- матрица объектов\n",
        "        y -- вектор ответов\n",
        "        feature_id -- айдишник признака, по которому делаем сплит\n",
        "        threshold -- порог, по которому делаем сплит\n",
        "        \"\"\"\n",
        "        left_mask = x[:, feature_id] > threshold\n",
        "        right_mask = ~left_mask\n",
        "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
        "    \n",
        "    def __gini(self, l_c, l_s, r_c, r_s):\n",
        "        l_s = l_s.astype('float').reshape(-1,1)\n",
        "        r_s = r_s.astype('float').reshape(-1,1)\n",
        "        total = (1 - np.sum(((l_c + r_c)/(l_s + r_s)) ** 2, axis=1)).reshape(-1, 1)\n",
        "        left = (1 - np.sum((l_c / l_s) ** 2, axis=1)).reshape(-1, 1) * l_s / (l_s + r_s)\n",
        "        right = (1 - np.sum((r_c / r_s) ** 2, axis=1)).reshape(-1, 1) * r_s / (l_s + r_s)\n",
        "        return total - (left + right)\n",
        "    \n",
        "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
        "        eps = np.random.rand() / 1e4\n",
        "        l_s = l_s.astype('float') + eps\n",
        "        r_s = r_s.astype('float') + eps\n",
        "        total = (-np.sum((l_c + r_c + eps) / (l_s + r_s) * \\\n",
        "                         np.log((l_c + r_c + eps) / (l_s + r_s)), axis=1)).reshape(-1, 1)\n",
        "        left = (-np.sum((l_c + eps) / l_s * np.log((l_c + eps) / l_s), axis=1))\\\n",
        "                .reshape(-1, 1) * l_s / (l_s + r_s)\n",
        "        right = (-np.sum(((r_c + eps) / r_s) * np.log((r_c + eps) / r_s), axis=1))\\\n",
        "                .reshape(-1, 1) * r_s / (l_s + r_s)\n",
        "        return total - (left + right)\n",
        "    \n",
        "    def __misclass(self,l_c, l_s, r_c, r_s):\n",
        "        l_s = l_s.astype('float')\n",
        "        r_s = r_s.astype('float')\n",
        "        total = (1 - np.max((l_c + r_c) / (l_s + r_s), axis=1)).reshape(-1, 1)\n",
        "        left = (1 - np.max(l_c / l_s, axis=1)).reshape(-1, 1) * l_s / (l_s + r_s)\n",
        "        right = (1 - np.max(r_c / r_s, axis=1)).reshape(-1, 1) * r_s / (l_s + r_s)\n",
        "        return total - (left + right)\n",
        "    \n",
        "    def __find_threshold(self, X, Y):\n",
        "        \"\"\"\n",
        "        Находим оптимальный признак и порог для сплита\n",
        "        Здесь используем разные impurity в зависимости от self.criterion\n",
        "        \"\"\"\n",
        "        thresholds = []\n",
        "        for feature in range(X.shape[1]):\n",
        "            x, y = X[:, feature], Y.copy()\n",
        "            idx_sort = np.argsort(x)\n",
        "            x = x[idx_sort]\n",
        "            y = y[idx_sort]\n",
        "            \n",
        "            label_change = np.where(y[1:] != y[:-1])[0] + 1\n",
        "            if label_change.size == 0:\n",
        "                return -np.inf, 0\n",
        "\n",
        "            index = np.zeros((label_change.shape[0], self.num_class))\n",
        "            index[np.arange(label_change.shape[0]), y[label_change - 1]] = 1\n",
        "\n",
        "            elems = np.append(0, label_change[:-1])\n",
        "            elem_count = index * (label_change - elems).reshape(-1, 1)\n",
        "            \n",
        "            left = np.cumsum(elem_count, axis=0)\n",
        "            right = np.bincount(y, minlength=self.num_class) - left\n",
        "            left_size = label_change.reshape(-1, 1)\n",
        "            right_size = y.shape[0] - left_size\n",
        "            \n",
        "            values = self.impurity(left, left_size, right, right_size)\n",
        "            idx_min = np.argmax(values)\n",
        "            thresholds.append([values[idx_min], (x[left_size[idx_min][0] - 1] + \\\n",
        "                                                 x[left_size[idx_min][0]]) / 2])\n",
        "        \n",
        "        thresholds = np.asarray(thresholds, dtype=object)\n",
        "        ind = np.argmax(thresholds[:, 0])\n",
        "        return ind, thresholds[ind]\n",
        "\n",
        "    def __make_leaf(self, y):\n",
        "        count = np.bincount(y)\n",
        "        return count.argmax(), count.max() / y.shape[0]\n",
        "        \n",
        "    def __fit_node(self, x, y, node_id, depth):\n",
        "        \"\"\"\n",
        "        Делаем новый узел в дереве\n",
        "        Решаем, терминальный он или нет\n",
        "        Если нет, то строим левый узел  с айди 2 * node_id + 1\n",
        "        И правый узел с  айди 2 * node_id + 2\n",
        "        \"\"\"\n",
        "\n",
        "        if depth == self.max_depth or y.size < self.min_samples_split or np.unique(y).size == 1:\n",
        "            label, p = self.__make_leaf(y)\n",
        "            self.tree[node_id] = (self.LEAF_TYPE, label, p)\n",
        "            return\n",
        "        \n",
        "        feature_id, th = self.__find_threshold(x, y)\n",
        "        self.feature_importances_[feature_id] += th[0]\n",
        "        \n",
        "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, feature_id, th[1])\n",
        "        if y_l.size == 0 or y_r.size == 0:\n",
        "            label, p = self.__make_leaf(y)\n",
        "            self.tree[node_id] = (self.LEAF_TYPE, label, p)\n",
        "            return\n",
        "        \n",
        "        self.tree[node_id] = (self.NON_LEAF_TYPE, feature_id, th[1])\n",
        "        self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
        "        self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
        "\n",
        "    \n",
        "    def fit(self, x, y):\n",
        "        \"\"\"\n",
        "        Рекурсивно строим дерево решений\n",
        "        Начинаем с корня node_id 0\n",
        "        \"\"\"\n",
        "        self.num_class = np.unique(y).size\n",
        "        self.__fit_node(x, y, 0, 0) \n",
        "\n",
        "    def __predict_class(self, x, node_id):\n",
        "        \"\"\"\n",
        "        Рекурсивно обходим дерево по всем узлам,\n",
        "        пока не дойдем до терминального\n",
        "        \"\"\"\n",
        "        node = self.tree[node_id]\n",
        "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
        "            _, feature_id, threshold = node\n",
        "            if x[feature_id] > threshold:\n",
        "                return self.__predict_class(x, 2 * node_id + 1)\n",
        "            else:\n",
        "                return self.__predict_class(x, 2 * node_id + 2)\n",
        "        else:\n",
        "            return node[1]\n",
        "        \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Вызывает predict для всех объектов из матрицы X\n",
        "        \"\"\"\n",
        "        return np.array([self.__predict_class(x, 0) for x in X])\n",
        "    \n",
        "    def fit_predict(self, x_train, y_train, predicted_x):\n",
        "        self.fit(x_train, y_train)\n",
        "        return self.predict(predicted_x)\n",
        "    \n",
        "    def get_feature_importance(self):\n",
        "        \"\"\"\n",
        "        Возвращает важность признаков\n",
        "        \"\"\"\n",
        "        return self.feature_importances_"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmW4DkO58-W8"
      },
      "source": [
        "wine = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, \n",
        "                                                    stratify=wine.target, random_state=42)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B49_IHWSZLN"
      },
      "source": [
        "clf = DecisionTreeClassifier(min_samples_split=2)\n",
        "my_clf = MyDecisionTreeClassifier(min_samples_split=2)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI4wHTWa8-W_",
        "outputId": "aa06cd2c-e8e6-4da1-81c0-5857a3765b1f"
      },
      "source": [
        "clf.fit(X_train, y_train)\n",
        "my_clf.fit(X_train, y_train)\n",
        "\n",
        "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
        "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9722222222222222\n",
            "0.9722222222222222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iJ1Y1eW8-XB"
      },
      "source": [
        "## Ускоряем дерево решений (2 балла)\n",
        "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine. \n",
        "Для этого используем numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mSFqwGi8-XN",
        "outputId": "eef2f960-b2f2-434d-be59-c8556566818b"
      },
      "source": [
        "%time clf.fit(X_train, y_train)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.2 ms, sys: 4 µs, total: 2.2 ms\n",
            "Wall time: 2.16 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpDwkNKO8-XO",
        "outputId": "40b1d48a-05e9-4f00-b827-5bfb4fa3e10c"
      },
      "source": [
        "%time my_clf.fit(X_train, y_train)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16.6 ms, sys: 0 ns, total: 16.6 ms\n",
            "Wall time: 17.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8snMOPu_8-XQ"
      },
      "source": [
        "## Боевое применение (3 балла)\n",
        "\n",
        "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match). \n",
        "\n",
        "Пример работы с датасетом можете найти в практике пункт 2\n",
        "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
        "\n",
        "Данные и описания колонок лежат тут\n",
        "https://cloud.mail.ru/public/8nHV/p6J7wY1y1/speed-dating-experiment/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByydUxTp8-XT"
      },
      "source": [
        "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "D23fxG_y8-XV",
        "outputId": "40682151-15dc-40a1-a4b0-3e8c7e90cb0a"
      },
      "source": [
        "df = pd.read_csv('sdd.csv', encoding='latin1')\n",
        "df.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iid</th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>match</th>\n",
              "      <th>int_corr</th>\n",
              "      <th>samerace</th>\n",
              "      <th>age_o</th>\n",
              "      <th>race_o</th>\n",
              "      <th>pf_o_att</th>\n",
              "      <th>pf_o_sin</th>\n",
              "      <th>pf_o_int</th>\n",
              "      <th>pf_o_fun</th>\n",
              "      <th>pf_o_amb</th>\n",
              "      <th>pf_o_sha</th>\n",
              "      <th>dec_o</th>\n",
              "      <th>attr_o</th>\n",
              "      <th>sinc_o</th>\n",
              "      <th>intel_o</th>\n",
              "      <th>fun_o</th>\n",
              "      <th>amb_o</th>\n",
              "      <th>shar_o</th>\n",
              "      <th>like_o</th>\n",
              "      <th>prob_o</th>\n",
              "      <th>met_o</th>\n",
              "      <th>age</th>\n",
              "      <th>field</th>\n",
              "      <th>field_cd</th>\n",
              "      <th>undergra</th>\n",
              "      <th>mn_sat</th>\n",
              "      <th>tuition</th>\n",
              "      <th>race</th>\n",
              "      <th>...</th>\n",
              "      <th>amb5_2</th>\n",
              "      <th>you_call</th>\n",
              "      <th>them_cal</th>\n",
              "      <th>date_3</th>\n",
              "      <th>numdat_3</th>\n",
              "      <th>num_in_3</th>\n",
              "      <th>attr1_3</th>\n",
              "      <th>sinc1_3</th>\n",
              "      <th>intel1_3</th>\n",
              "      <th>fun1_3</th>\n",
              "      <th>amb1_3</th>\n",
              "      <th>shar1_3</th>\n",
              "      <th>attr7_3</th>\n",
              "      <th>sinc7_3</th>\n",
              "      <th>intel7_3</th>\n",
              "      <th>fun7_3</th>\n",
              "      <th>amb7_3</th>\n",
              "      <th>shar7_3</th>\n",
              "      <th>attr4_3</th>\n",
              "      <th>sinc4_3</th>\n",
              "      <th>intel4_3</th>\n",
              "      <th>fun4_3</th>\n",
              "      <th>amb4_3</th>\n",
              "      <th>shar4_3</th>\n",
              "      <th>attr2_3</th>\n",
              "      <th>sinc2_3</th>\n",
              "      <th>intel2_3</th>\n",
              "      <th>fun2_3</th>\n",
              "      <th>amb2_3</th>\n",
              "      <th>shar2_3</th>\n",
              "      <th>attr3_3</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.16</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 195 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   iid   id  gender  idg  condtn  ...  attr5_3  sinc5_3  intel5_3  fun5_3  amb5_3\n",
              "0    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "1    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "2    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "3    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "4    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "\n",
              "[5 rows x 195 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "eEepSY8o8-XX"
      },
      "source": [
        "df = df.iloc[:, :97]\n",
        "df = df.drop(['id', 'idg', 'condtn', 'round', 'position',\n",
        "              'positin1', 'order', 'partner', 'age_o', 'race_o',\n",
        "              'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun',\n",
        "              'pf_o_amb', 'pf_o_sha', 'dec_o', 'attr_o',\n",
        "              'sinc_o', 'intel_o',  'amb_o',\n",
        "              'shar_o',  'prob_o', 'met_o'], axis=1)\n",
        "\n",
        "df = df.dropna(subset=['age'])\n",
        "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].dropna()\n",
        "df = df.drop(['field'], axis=1)\n",
        "\n",
        "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
        "df.loc[:, 'mn_sat'] = df.mn_sat.dropna()\n",
        "df = df.drop(['undergra'], axis=1)\n",
        "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
        "df.loc[:, 'tuition'] = df.tuition.dropna()\n",
        "df = df.dropna(subset=['imprelig', 'imprace'])\n",
        "df = df.drop(['from', 'zipcode'], axis=1)\n",
        "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
        "df.loc[:, 'income'] = df.loc[:, 'income'].dropna()\n",
        "df = df.dropna(subset=['date'])\n",
        "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].dropna()\n",
        "df = df.drop(['career'], axis=1)\n",
        "df = df.drop(['sports', 'tvsports', 'exercise', 'dining',\n",
        "              'museums', 'art', 'hiking', 'gaming',\n",
        "              'clubbing', 'reading', 'tv', 'theater',\n",
        "              'movies', 'concerts', 'music', 'shopping', 'yoga'], axis=1)\n",
        "df = df.drop(['expnum'], axis=1)\n",
        "\n",
        "\n",
        "feat = ['iid', 'wave', 'attr1_1', 'sinc1_1',\n",
        "        'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']\n",
        "\n",
        "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
        "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1',\n",
        "                                        'intel1_1', 'fun1_1',\n",
        "                                        'amb1_1', 'shar1_1']].sum(axis=1)\n",
        "\n",
        "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
        "           'fun1_1', 'amb1_1', 'shar1_1']] = (\n",
        "    df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
        "               'fun1_1', 'amb1_1', 'shar1_1']].T /\n",
        "    df.loc[:, 'temp_totalsum'].T).T * 100\n",
        "\n",
        "\n",
        "feat = ['iid', 'wave', 'attr2_1', 'sinc2_1',\n",
        "        'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']\n",
        "\n",
        "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
        "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
        "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1',\n",
        "                                      'intel2_1', 'fun2_1',\n",
        "                                      'amb2_1', 'shar2_1']].sum(axis=1)\n",
        "\n",
        "df.loc[:, ['attr2_1', 'sinc2_1',\n",
        "           'intel2_1', 'fun2_1',\n",
        "           'amb2_1', 'shar2_1']] = (\n",
        "    df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
        "               'fun2_1', 'amb2_1', 'shar2_1']].T /\n",
        "    df.loc[:, 'temp_totalsum'].T).T * 100\n",
        "\n",
        "df = df.drop(['temp_totalsum'], axis=1)\n",
        "\n",
        "\n",
        "for i in [4, 5]:\n",
        "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i),\n",
        "            'intel{}_1'.format(i), 'fun{}_1'.format(i),\n",
        "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
        "    if i != 4:\n",
        "        feat.remove('shar{}_1'.format(i))\n",
        "    df = df.drop(feat, axis=1)\n",
        "\n",
        "    \n",
        "df = df.drop(['wave'], axis=1)\n",
        "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
        "    .drop(['gender'], axis=1).dropna()\n",
        "\n",
        "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
        "    .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1).dropna()\n",
        "\n",
        "df_female.columns = df_female.columns + '_f'"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "IxxS9HoK-5V7",
        "outputId": "26f50677-e406-4f44-899a-dc0085a57689"
      },
      "source": [
        "df = df_male.merge(df_female, how='inner', left_on='pid', right_on='iid_f')\n",
        "df"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iid</th>\n",
              "      <th>pid</th>\n",
              "      <th>match</th>\n",
              "      <th>int_corr</th>\n",
              "      <th>samerace</th>\n",
              "      <th>fun_o</th>\n",
              "      <th>like_o</th>\n",
              "      <th>age</th>\n",
              "      <th>field_cd</th>\n",
              "      <th>mn_sat</th>\n",
              "      <th>tuition</th>\n",
              "      <th>race</th>\n",
              "      <th>imprace</th>\n",
              "      <th>imprelig</th>\n",
              "      <th>income</th>\n",
              "      <th>goal</th>\n",
              "      <th>date</th>\n",
              "      <th>go_out</th>\n",
              "      <th>career_c</th>\n",
              "      <th>exphappy</th>\n",
              "      <th>attr1_1</th>\n",
              "      <th>sinc1_1</th>\n",
              "      <th>intel1_1</th>\n",
              "      <th>fun1_1</th>\n",
              "      <th>amb1_1</th>\n",
              "      <th>shar1_1</th>\n",
              "      <th>attr2_1</th>\n",
              "      <th>sinc2_1</th>\n",
              "      <th>intel2_1</th>\n",
              "      <th>fun2_1</th>\n",
              "      <th>amb2_1</th>\n",
              "      <th>shar2_1</th>\n",
              "      <th>attr3_1</th>\n",
              "      <th>sinc3_1</th>\n",
              "      <th>fun3_1</th>\n",
              "      <th>intel3_1</th>\n",
              "      <th>amb3_1</th>\n",
              "      <th>iid_f</th>\n",
              "      <th>pid_f</th>\n",
              "      <th>fun_o_f</th>\n",
              "      <th>like_o_f</th>\n",
              "      <th>age_f</th>\n",
              "      <th>field_cd_f</th>\n",
              "      <th>mn_sat_f</th>\n",
              "      <th>tuition_f</th>\n",
              "      <th>race_f</th>\n",
              "      <th>imprace_f</th>\n",
              "      <th>imprelig_f</th>\n",
              "      <th>income_f</th>\n",
              "      <th>goal_f</th>\n",
              "      <th>date_f</th>\n",
              "      <th>go_out_f</th>\n",
              "      <th>career_c_f</th>\n",
              "      <th>exphappy_f</th>\n",
              "      <th>attr1_1_f</th>\n",
              "      <th>sinc1_1_f</th>\n",
              "      <th>intel1_1_f</th>\n",
              "      <th>fun1_1_f</th>\n",
              "      <th>amb1_1_f</th>\n",
              "      <th>shar1_1_f</th>\n",
              "      <th>attr2_1_f</th>\n",
              "      <th>sinc2_1_f</th>\n",
              "      <th>intel2_1_f</th>\n",
              "      <th>fun2_1_f</th>\n",
              "      <th>amb2_1_f</th>\n",
              "      <th>shar2_1_f</th>\n",
              "      <th>attr3_1_f</th>\n",
              "      <th>sinc3_1_f</th>\n",
              "      <th>fun3_1_f</th>\n",
              "      <th>intel3_1_f</th>\n",
              "      <th>amb3_1_f</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>246</td>\n",
              "      <td>234.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>9168.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41476.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>5.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>234</td>\n",
              "      <td>243.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1070.0</td>\n",
              "      <td>12696.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44346.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>248</td>\n",
              "      <td>234.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1360.0</td>\n",
              "      <td>26062.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49841.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>15.00000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>234</td>\n",
              "      <td>243.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1070.0</td>\n",
              "      <td>12696.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44346.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>246</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>9168.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41476.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>5.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>236</td>\n",
              "      <td>243.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>26630.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>42225.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>248</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1360.0</td>\n",
              "      <td>26062.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49841.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>15.00000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>236</td>\n",
              "      <td>243.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>26630.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>42225.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>246</td>\n",
              "      <td>237.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>9168.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41476.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>5.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>237</td>\n",
              "      <td>243.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1290.0</td>\n",
              "      <td>15309.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>37405.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>535</td>\n",
              "      <td>527.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1210.0</td>\n",
              "      <td>23500.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>48137.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>15.00000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>527</td>\n",
              "      <td>531.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1290.0</td>\n",
              "      <td>15309.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32386.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>537</td>\n",
              "      <td>527.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1309.0</td>\n",
              "      <td>15162.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>61686.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>9.52381</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>23.809524</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>23.809524</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>527</td>\n",
              "      <td>531.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1290.0</td>\n",
              "      <td>15309.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32386.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>543</td>\n",
              "      <td>527.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1320.0</td>\n",
              "      <td>25533.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>47624.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>16.00000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>527</td>\n",
              "      <td>531.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1290.0</td>\n",
              "      <td>15309.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32386.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>544</td>\n",
              "      <td>527.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1309.0</td>\n",
              "      <td>15162.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>36673.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.00000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>527</td>\n",
              "      <td>531.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1290.0</td>\n",
              "      <td>15309.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32386.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>551</td>\n",
              "      <td>527.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>26019.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>55138.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>527</td>\n",
              "      <td>531.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1290.0</td>\n",
              "      <td>15309.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32386.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>308 rows × 71 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     iid    pid  match  int_corr  ...  sinc3_1_f  fun3_1_f  intel3_1_f  amb3_1_f\n",
              "0    246  234.0      0      0.44  ...        7.0       8.0         8.0      10.0\n",
              "1    248  234.0      0      0.23  ...        7.0       8.0         8.0      10.0\n",
              "2    246  236.0      0      0.26  ...        9.0      10.0         8.0       8.0\n",
              "3    248  236.0      0     -0.03  ...        9.0      10.0         8.0       8.0\n",
              "4    246  237.0      0      0.24  ...       10.0       7.0         8.0       8.0\n",
              "..   ...    ...    ...       ...  ...        ...       ...         ...       ...\n",
              "303  535  527.0      0      0.35  ...       10.0      10.0        10.0      10.0\n",
              "304  537  527.0      0      0.62  ...       10.0      10.0        10.0      10.0\n",
              "305  543  527.0      0      0.13  ...       10.0      10.0        10.0      10.0\n",
              "306  544  527.0      0      0.17  ...       10.0      10.0        10.0      10.0\n",
              "307  551  527.0      0      0.29  ...       10.0      10.0        10.0      10.0\n",
              "\n",
              "[308 rows x 71 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQf-izFe_kFA",
        "outputId": "4d10eeff-dbab-41c7-ec23-fc839b5a7dd2"
      },
      "source": [
        "X = df.drop(['match', 'iid', 'pid', 'iid_f', 'pid_f'], axis=1)\n",
        "y = df['match']\n",
        "\n",
        "X_ = X.values\n",
        "y_ = y.values\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((308, 66), (308,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNhd0-_OAX8o"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_, y_, random_state=42)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzjiZ0Ht_8kI",
        "outputId": "0ec0b0cd-c455-4851-994a-9418c720c280"
      },
      "source": [
        "clf = DecisionTreeClassifier(min_samples_split=2)\n",
        "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "my_clf.fit(X_train, y_train)\n",
        "\n",
        "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
        "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8571428571428571\n",
            "0.922077922077922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fHFzVEr8-XY"
      },
      "source": [
        "Разбейте датасет на трейн и валидацию. Подберите на валидации оптимальный критерий  информативности. \n",
        "Постройте графики зависимости точности на валидации от глубины дерева, от минимального числа объектов для сплита. \n",
        "Какой максимальной точности удалось достигнуть?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzZOnZMy8-XZ",
        "outputId": "48e44df6-048f-484a-fe52-93fec870ca44"
      },
      "source": [
        "scores = defaultdict(list)\n",
        "min_splits = range(2, 11)\n",
        "max_depths = range(1, 11)\n",
        "criterions = ['gini', 'entropy', 'misclass']\n",
        "for split in min_splits:\n",
        "    for depth in max_depths:\n",
        "        for crit in criterions:\n",
        "            iter_score = []\n",
        "            for train, val in KFold(n_splits=3, shuffle=True).split(X_, y_):\n",
        "                my_clf = MyDecisionTreeClassifier(criterion=crit, \n",
        "                                                  max_depth=depth,\n",
        "                                                  min_samples_split=split)\n",
        "                my_clf.fit(X_[train], y_[train])\n",
        "                iter_score.append(accuracy_score(y_[val], my_clf.predict(X_[val])))\n",
        "            print(f\"{np.mean(iter_score)} -- ({crit}, {split}, {depth})\")\n",
        "            scores[np.mean(iter_score)].append((crit, split, depth))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8701694269940986 -- (gini, 2, 1)\n",
            "0.869979059584999 -- (entropy, 2, 1)\n",
            "0.8637603908877467 -- (misclass, 2, 1)\n",
            "0.8538612856145695 -- (gini, 2, 2)\n",
            "0.8602385938194047 -- (entropy, 2, 2)\n",
            "0.8700742432895489 -- (misclass, 2, 2)\n",
            "0.8765784631004506 -- (gini, 2, 3)\n",
            "0.8571292594707787 -- (entropy, 2, 3)\n",
            "0.8668379973348562 -- (misclass, 2, 3)\n",
            "0.8504981280538105 -- (gini, 2, 4)\n",
            "0.8376166000380735 -- (entropy, 2, 4)\n",
            "0.8505933117583604 -- (misclass, 2, 4)\n",
            "0.8506567675613934 -- (gini, 2, 5)\n",
            "0.8538930135160862 -- (entropy, 2, 5)\n",
            "0.8506250396598768 -- (misclass, 2, 5)\n",
            "0.8767053747065169 -- (gini, 2, 6)\n",
            "0.8540199251221524 -- (entropy, 2, 6)\n",
            "0.8669014531378895 -- (misclass, 2, 6)\n",
            "0.8376800558411066 -- (gini, 2, 7)\n",
            "0.8538930135160859 -- (entropy, 2, 7)\n",
            "0.8667428136303066 -- (misclass, 2, 7)\n",
            "0.8701694269940986 -- (gini, 2, 8)\n",
            "0.8312075639317215 -- (entropy, 2, 8)\n",
            "0.8603972333269878 -- (misclass, 2, 8)\n",
            "0.8604606891300209 -- (gini, 2, 9)\n",
            "0.8540199251221524 -- (entropy, 2, 9)\n",
            "0.873342217145758 -- (misclass, 2, 9)\n",
            "0.8538930135160859 -- (gini, 2, 10)\n",
            "0.8505933117583604 -- (entropy, 2, 10)\n",
            "0.8702011548956152 -- (misclass, 2, 10)\n",
            "0.8701694269940985 -- (gini, 3, 1)\n",
            "0.8701694269940985 -- (entropy, 3, 1)\n",
            "0.866869725236373 -- (misclass, 3, 1)\n",
            "0.8701694269940985 -- (gini, 3, 2)\n",
            "0.8506567675613934 -- (entropy, 3, 2)\n",
            "0.869979059584999 -- (misclass, 3, 2)\n",
            "0.8603337775239547 -- (gini, 3, 3)\n",
            "0.8377117837426232 -- (entropy, 3, 3)\n",
            "0.8669331810394061 -- (misclass, 3, 3)\n",
            "0.8473570658036677 -- (gini, 3, 4)\n",
            "0.8541151088267022 -- (entropy, 3, 4)\n",
            "0.8700107874865157 -- (misclass, 3, 4)\n",
            "0.8378386953486897 -- (gini, 3, 5)\n",
            "0.8311123802271717 -- (entropy, 3, 5)\n",
            "0.8701376990925821 -- (misclass, 3, 5)\n",
            "0.8732470334412082 -- (gini, 3, 6)\n",
            "0.8406942064851831 -- (entropy, 3, 6)\n",
            "0.8701059711910655 -- (misclass, 3, 6)\n",
            "0.8669966368424392 -- (gini, 3, 7)\n",
            "0.866869725236373 -- (entropy, 3, 7)\n",
            "0.8701694269940986 -- (misclass, 3, 7)\n",
            "0.8472618820991179 -- (gini, 3, 8)\n",
            "0.8538295577130528 -- (entropy, 3, 8)\n",
            "0.8700425153880323 -- (misclass, 3, 8)\n",
            "0.8409163017957991 -- (gini, 3, 9)\n",
            "0.8473253379021513 -- (entropy, 3, 9)\n",
            "0.857256171076845 -- (misclass, 3, 9)\n",
            "0.8539247414176027 -- (gini, 3, 10)\n",
            "0.8016688876197727 -- (entropy, 3, 10)\n",
            "0.8701059711910655 -- (misclass, 3, 10)\n",
            "0.8701694269940985 -- (gini, 4, 1)\n",
            "0.8702328827971318 -- (entropy, 4, 1)\n",
            "0.8667745415318232 -- (misclass, 4, 1)\n",
            "0.8504981280538105 -- (gini, 4, 2)\n",
            "0.8472618820991181 -- (entropy, 4, 2)\n",
            "0.8700742432895489 -- (misclass, 4, 2)\n",
            "0.8183260359159844 -- (gini, 4, 3)\n",
            "0.857256171076845 -- (entropy, 4, 3)\n",
            "0.8765150072974174 -- (misclass, 4, 3)\n",
            "0.8279078621739958 -- (gini, 4, 4)\n",
            "0.8081731074306745 -- (entropy, 4, 4)\n",
            "0.8701694269940986 -- (misclass, 4, 4)\n",
            "0.8668379973348563 -- (gini, 4, 5)\n",
            "0.840852845992766 -- (entropy, 4, 5)\n",
            "0.8670600926454725 -- (misclass, 4, 5)\n",
            "0.8571927152738118 -- (gini, 4, 6)\n",
            "0.8603337775239547 -- (entropy, 4, 6)\n",
            "0.869979059584999 -- (misclass, 4, 6)\n",
            "0.8278444063709628 -- (gini, 4, 7)\n",
            "0.8800050764642426 -- (entropy, 4, 7)\n",
            "0.8669014531378894 -- (misclass, 4, 7)\n",
            "0.8540199251221524 -- (gini, 4, 8)\n",
            "0.8409797575988325 -- (entropy, 4, 8)\n",
            "0.8702646106986484 -- (misclass, 4, 8)\n",
            "0.8636334792816803 -- (gini, 4, 9)\n",
            "0.8636969350847133 -- (entropy, 4, 9)\n",
            "0.8538612856145695 -- (misclass, 4, 9)\n",
            "0.8928231486769466 -- (gini, 4, 10)\n",
            "0.8472301541976014 -- (entropy, 4, 10)\n",
            "0.8668062694333397 -- (misclass, 4, 10)\n",
            "0.8701694269940986 -- (gini, 5, 1)\n",
            "0.8701376990925821 -- (entropy, 5, 1)\n",
            "0.8733104892442415 -- (misclass, 5, 1)\n",
            "0.8700742432895489 -- (gini, 5, 2)\n",
            "0.8699156037819659 -- (entropy, 5, 2)\n",
            "0.8733104892442415 -- (misclass, 5, 2)\n",
            "0.8539881972206359 -- (gini, 5, 3)\n",
            "0.8635700234786472 -- (entropy, 5, 3)\n",
            "0.8701694269940986 -- (misclass, 5, 3)\n",
            "0.8702328827971318 -- (gini, 5, 4)\n",
            "0.8605876007360873 -- (entropy, 5, 4)\n",
            "0.8767371026080335 -- (misclass, 5, 4)\n",
            "0.8732470334412082 -- (gini, 5, 5)\n",
            "0.8176914778856527 -- (entropy, 5, 5)\n",
            "0.8570023478647123 -- (misclass, 5, 5)\n",
            "0.8376800558411066 -- (gini, 5, 6)\n",
            "0.8440890919474585 -- (entropy, 5, 6)\n",
            "0.8669331810394061 -- (misclass, 5, 6)\n",
            "0.8538612856145694 -- (gini, 5, 7)\n",
            "0.8571609873722951 -- (entropy, 5, 7)\n",
            "0.8766419189034838 -- (misclass, 5, 7)\n",
            "0.8603020496224381 -- (gini, 5, 8)\n",
            "0.8472936100006345 -- (entropy, 5, 8)\n",
            "0.8701694269940985 -- (misclass, 5, 8)\n",
            "0.8473570658036677 -- (gini, 5, 9)\n",
            "0.8472301541976014 -- (entropy, 5, 9)\n",
            "0.8701376990925821 -- (misclass, 5, 9)\n",
            "0.8474522495082176 -- (gini, 5, 10)\n",
            "0.8473253379021511 -- (entropy, 5, 10)\n",
            "0.8734374008503077 -- (misclass, 5, 10)\n",
            "0.8669331810394061 -- (gini, 6, 1)\n",
            "0.8701376990925821 -- (entropy, 6, 1)\n",
            "0.8700425153880323 -- (misclass, 6, 1)\n",
            "0.8473253379021511 -- (gini, 6, 2)\n",
            "0.8700107874865157 -- (entropy, 6, 2)\n",
            "0.8702328827971318 -- (misclass, 6, 2)\n",
            "0.8539881972206359 -- (gini, 6, 3)\n",
            "0.8604289612285044 -- (entropy, 6, 3)\n",
            "0.8701376990925821 -- (misclass, 6, 3)\n",
            "0.847483977409734 -- (gini, 6, 4)\n",
            "0.8442477314550416 -- (entropy, 6, 4)\n",
            "0.863665207183197 -- (misclass, 6, 4)\n",
            "0.8409163017957991 -- (gini, 6, 5)\n",
            "0.85068849546291 -- (entropy, 6, 5)\n",
            "0.857256171076845 -- (misclass, 6, 5)\n",
            "0.8508154070689765 -- (gini, 6, 6)\n",
            "0.831175836030205 -- (entropy, 6, 6)\n",
            "0.8474522495082176 -- (misclass, 6, 6)\n",
            "0.8604289612285044 -- (gini, 6, 7)\n",
            "0.8668379973348562 -- (entropy, 6, 7)\n",
            "0.8700742432895489 -- (misclass, 6, 7)\n",
            "0.8605558728345707 -- (gini, 6, 8)\n",
            "0.8829557713052859 -- (entropy, 6, 8)\n",
            "0.8701059711910654 -- (misclass, 6, 8)\n",
            "0.8407893901897329 -- (gini, 6, 9)\n",
            "0.8474522495082176 -- (entropy, 6, 9)\n",
            "0.873342217145758 -- (misclass, 6, 9)\n",
            "0.8409480296973157 -- (gini, 6, 10)\n",
            "0.8149946062567421 -- (entropy, 6, 10)\n",
            "0.8832095945174187 -- (misclass, 6, 10)\n",
            "0.8700425153880323 -- (gini, 7, 1)\n",
            "0.8702011548956152 -- (entropy, 7, 1)\n",
            "0.8732153055396917 -- (misclass, 7, 1)\n",
            "0.8700107874865157 -- (gini, 7, 2)\n",
            "0.8698521479789326 -- (entropy, 7, 2)\n",
            "0.8702011548956152 -- (misclass, 7, 2)\n",
            "0.8571292594707786 -- (gini, 7, 3)\n",
            "0.8441208198489752 -- (entropy, 7, 3)\n",
            "0.8701694269940986 -- (misclass, 7, 3)\n",
            "0.8669331810394061 -- (gini, 7, 4)\n",
            "0.866869725236373 -- (entropy, 7, 4)\n",
            "0.8733739450472746 -- (misclass, 7, 4)\n",
            "0.8831144108128689 -- (gini, 7, 5)\n",
            "0.8702328827971318 -- (entropy, 7, 5)\n",
            "0.8702646106986484 -- (misclass, 7, 5)\n",
            "0.8345389935909638 -- (gini, 7, 6)\n",
            "0.8312710197347547 -- (entropy, 7, 6)\n",
            "0.8700425153880323 -- (misclass, 7, 6)\n",
            "0.866869725236373 -- (gini, 7, 7)\n",
            "0.8441208198489752 -- (entropy, 7, 7)\n",
            "0.8669331810394061 -- (misclass, 7, 7)\n",
            "0.8765784631004506 -- (gini, 7, 8)\n",
            "0.854051653023669 -- (entropy, 7, 8)\n",
            "0.8701376990925821 -- (misclass, 7, 8)\n",
            "0.8311441081286883 -- (gini, 7, 9)\n",
            "0.8084903864458405 -- (entropy, 7, 9)\n",
            "0.866869725236373 -- (misclass, 7, 9)\n",
            "0.8604606891300209 -- (gini, 7, 10)\n",
            "0.8343486261818643 -- (entropy, 7, 10)\n",
            "0.8701694269940986 -- (misclass, 7, 10)\n",
            "0.8604289612285044 -- (gini, 8, 1)\n",
            "0.8702011548956152 -- (entropy, 8, 1)\n",
            "0.8669331810394061 -- (misclass, 8, 1)\n",
            "0.8344438098864141 -- (gini, 8, 2)\n",
            "0.8669331810394061 -- (entropy, 8, 2)\n",
            "0.8702328827971318 -- (misclass, 8, 2)\n",
            "0.8603337775239545 -- (gini, 8, 3)\n",
            "0.8636969350847133 -- (entropy, 8, 3)\n",
            "0.8765784631004506 -- (misclass, 8, 3)\n",
            "0.8506567675613934 -- (gini, 8, 4)\n",
            "0.8148676946506758 -- (entropy, 8, 4)\n",
            "0.8637286629862301 -- (misclass, 8, 4)\n",
            "0.8604924170315376 -- (gini, 8, 5)\n",
            "0.8570023478647123 -- (entropy, 8, 5)\n",
            "0.8702011548956152 -- (misclass, 8, 5)\n",
            "0.857256171076845 -- (gini, 8, 6)\n",
            "0.8378386953486897 -- (entropy, 8, 6)\n",
            "0.8636969350847133 -- (misclass, 8, 6)\n",
            "0.8538930135160859 -- (gini, 8, 7)\n",
            "0.8473253379021511 -- (entropy, 8, 7)\n",
            "0.8670283647439558 -- (misclass, 8, 7)\n",
            "0.8538295577130528 -- (gini, 8, 8)\n",
            "0.8474522495082176 -- (entropy, 8, 8)\n",
            "0.8537978298115364 -- (misclass, 8, 8)\n",
            "0.8312075639317215 -- (gini, 8, 9)\n",
            "0.8604289612285042 -- (entropy, 8, 9)\n",
            "0.8731201218351418 -- (misclass, 8, 9)\n",
            "0.8733739450472746 -- (gini, 8, 10)\n",
            "0.850625039659877 -- (entropy, 8, 10)\n",
            "0.8538612856145695 -- (misclass, 8, 10)\n",
            "0.8538295577130528 -- (gini, 9, 1)\n",
            "0.8701694269940985 -- (entropy, 9, 1)\n",
            "0.8703280665016816 -- (misclass, 9, 1)\n",
            "0.8669014531378894 -- (gini, 9, 2)\n",
            "0.844279459356558 -- (entropy, 9, 2)\n",
            "0.8700425153880323 -- (misclass, 9, 2)\n",
            "0.8570658036677455 -- (gini, 9, 3)\n",
            "0.8669331810394061 -- (entropy, 9, 3)\n",
            "0.8702328827971318 -- (misclass, 9, 3)\n",
            "0.8439939082429088 -- (gini, 9, 4)\n",
            "0.8570023478647123 -- (entropy, 9, 4)\n",
            "0.8702011548956152 -- (misclass, 9, 4)\n",
            "0.8409163017957991 -- (gini, 9, 5)\n",
            "0.8408211180912494 -- (entropy, 9, 5)\n",
            "0.8604924170315376 -- (misclass, 9, 5)\n",
            "0.8603020496224381 -- (gini, 9, 6)\n",
            "0.8507836791674599 -- (entropy, 9, 6)\n",
            "0.8701059711910654 -- (misclass, 9, 6)\n",
            "0.8440890919474585 -- (gini, 9, 7)\n",
            "0.8407576622882162 -- (entropy, 9, 7)\n",
            "0.8667745415318232 -- (misclass, 9, 7)\n",
            "0.8668379973348562 -- (gini, 9, 8)\n",
            "0.8312075639317215 -- (entropy, 9, 8)\n",
            "0.8700107874865157 -- (misclass, 9, 8)\n",
            "0.837806967447173 -- (gini, 9, 9)\n",
            "0.8441842756520083 -- (entropy, 9, 9)\n",
            "0.8702328827971318 -- (misclass, 9, 9)\n",
            "0.8441525477504919 -- (gini, 9, 10)\n",
            "0.8505615838568437 -- (entropy, 9, 10)\n",
            "0.8539564693191192 -- (misclass, 9, 10)\n",
            "0.8700742432895489 -- (gini, 10, 1)\n",
            "0.863665207183197 -- (entropy, 10, 1)\n",
            "0.8635700234786472 -- (misclass, 10, 1)\n",
            "0.8667110857287899 -- (gini, 10, 2)\n",
            "0.869979059584999 -- (entropy, 10, 2)\n",
            "0.8603337775239547 -- (misclass, 10, 2)\n",
            "0.863665207183197 -- (gini, 10, 3)\n",
            "0.8377752395456565 -- (entropy, 10, 3)\n",
            "0.8572244431753283 -- (misclass, 10, 3)\n",
            "0.8539881972206359 -- (gini, 10, 4)\n",
            "0.8312075639317215 -- (entropy, 10, 4)\n",
            "0.8701059711910654 -- (misclass, 10, 4)\n",
            "0.8473887937051844 -- (gini, 10, 5)\n",
            "0.827971317977029 -- (entropy, 10, 5)\n",
            "0.866869725236373 -- (misclass, 10, 5)\n",
            "0.8441525477504919 -- (gini, 10, 6)\n",
            "0.8377435116441397 -- (entropy, 10, 6)\n",
            "0.8700107874865157 -- (misclass, 10, 6)\n",
            "0.873342217145758 -- (gini, 10, 7)\n",
            "0.8667745415318232 -- (entropy, 10, 7)\n",
            "0.8702011548956152 -- (misclass, 10, 7)\n",
            "0.8603655054254711 -- (gini, 10, 8)\n",
            "0.8409797575988325 -- (entropy, 10, 8)\n",
            "0.8636969350847133 -- (misclass, 10, 8)\n",
            "0.8441525477504919 -- (gini, 10, 9)\n",
            "0.8473887937051843 -- (entropy, 10, 9)\n",
            "0.8667745415318232 -- (misclass, 10, 9)\n",
            "0.8701694269940986 -- (gini, 10, 10)\n",
            "0.8279713179770289 -- (entropy, 10, 10)\n",
            "0.8669014531378895 -- (misclass, 10, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9PsqzyB8-Xb",
        "outputId": "9c2d0bec-8a8f-4e15-e3d5-f2e5a21e3e85"
      },
      "source": [
        "np.max(list(scores.keys())), scores[np.max(list(scores.keys()))]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8928231486769466, [('gini', 4, 10)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luOyJh1ODcj7"
      },
      "source": [
        "depth_score = defaultdict(float)\n",
        "split_score = defaultdict(float)\n",
        "\n",
        "for item in scores.items():\n",
        "    for elem in item[1]:\n",
        "        depth_score[elem[2]] += item[0]\n",
        "        split_score[elem[1]] += item[0]\n",
        "\n",
        "for key in depth_score.keys():\n",
        "    depth_score[key] /= 9 * 3\n",
        "\n",
        "for key in split_score.keys():\n",
        "    split_score[key] /= 10 * 3"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "rkcg7yH_EKbR",
        "outputId": "b4a03951-e5b3-4945-d5f2-c8e768c57570"
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.scatter(list(depth_score.keys()), list(depth_score.values()))\n",
        "plt.xlabel('max_depth')\n",
        "plt.ylabel('score')\n",
        "plt.title('Val score for different max_depth')\n",
        "plt.show()\n",
        "plt.show()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAFOCAYAAABaLaGCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbxdVX3v+8+XJJSgQhRSryTEoEIkgpfgltb6RIsY5FRB2tOCoKJUqi1YlWKhclqK3uoRRe05igUfQKxStJRGoUYvpXJVbNkhQAwYDaiQBDWAUZEcCeF3/5hz08V2J9khe7JWdj7v12u9MueYD2uMtWeS7x5rjDlTVUiSJEnqzk79roAkSZI02Rm6JUmSpI4ZuiVJkqSOGbolSZKkjhm6JUmSpI4ZuiVJkqSOGbolTQpJKskz+l2P8UgyPckXkvw0yec6eo+HP48kH03yP3q2vSnJj5Lcl2SPJM9P8t12/egu6jOZJDkxydc6OvehSVZ1cW5J/WXoljQQknwpyTljlB+V5IdJpvajXh35feDJwB5V9d+7frOqemNVvRMgyTTgPOClVfX4qroHOAf43+36FV3Xp1eSi5K867F8z0GyPf2yKGnbGLolDYqLgROSZFT5q4F/qKoH+1CncUkyZSsPeSrwnUfTpgn45ePJwC7A8lH1WT727p3XR5J2CIZuSYPiCmAP4IUjBUmeCPwu8KkkhyS5Lsm6JHcl+d9Jdh7PidvhALcn+XmS7yU5vmfbG5Lc2m67JcnBbfn+Sf69fb/lSV7Rc8xFSc5PclWSXwC/nWSvJP+UZG37Hm/eRF3+Bvgr4A/b4RwnJdkpyVlJfpDkx0k+lWT3dv+5bW/oSUnuAP5tE+c9vf1c1iR5/ahtFyV5V5L9gBVt8bok/5bkNuBpwBfa+vxakt2TfLw93+r22Ck9n+XXk3wgyT3A2e0x70tyRzts5aNJprf7H5pkVZLT2rbdleR17baTgeOBt7fv/YVNtK2S/Ek7BObnSd6Z5OlJvpHkZ0kuG7kWkjwxyRfbn8NP2uXZ7bYntXV5ebv++CQrk7xmE5fOyPvvkWRR+17/CTx91PZnJvlKknuTrEjyB6M++4+223+e5KtJntpuu7bd7aa2/X/Yc9yvfF6StnNV5cuXL18D8QIuBD7Ws/7HwI3t8nOA3wSmAnOBW4G39OxbwDPGOOfjgJ8B89r1pwDPapf/O7AaeC4Q4Bk0vb7TgJXAXwI7A78D/LznHBcBPwWeT9N5sSuwhCZM70wTYm8HFm6inWcDn+5Zf337fk8DHg9cDlzSbpvbtu1TbVumj3G+I4AfAQe0+3ym9/No6/uuUeeb2nP894GX9Kz/M/D37bl+HfhP4I/bbScCDwKntj+L6cAHgEXAk4AnAF8A3t3uf2i7/znt53okcD/wxNF128x1UcC/ALsBzwJ+CVzdfl67A7cAr2333QP4vfZn8gTgc8AVPed6KfDDtl0XAp8fx3V5KXBZ+3kc0F4zX+u5vu4EXtd+HguAu4H5Pe37OfAi4NeAD40cO9Z1u6XPy5cvX9vvy55uSYPkYuD3k+zSrr+mLaOqllTVN6vqwar6Pk0ofPE4z/sQcECS6VV1V1WNDKX4I+C9VXV9NVZW1Q9owv3jgfdU1QNV9W/AF4Hjes75L1X19ap6CDgQmFlV57T7304T6I4dZ/2OB86rqtur6j7gTODYPHLoxtlV9YuqWj/G8X8AfLKqvlVVv6AJ9Y9KkifTBL23tO/3Y5pQ3duWNVX1v6oZHvN/gJOBt1bVvVX1c+BvR+2/ATinqjZU1VXAfcC8razae6vqZ+3P7lvAl9vP66fAv9KEXarqnqr6p6q6v63L/0PPdVJVX6YJ4le37fzjLXweU2hC/F+1n8e3aK/J1u8C36+qT7bX5lLgn2h+oRtxZVVdW1W/BN4BPC/J3pt524n4vCQNGMfiSRoYVfW1JHcDRye5HjgEOAagHRpxHjBE04s5laZ3eUvn/EX7tf2fAx9P8nXgtKr6NrA3cNsYh+0F3NkG6hE/AGb1rN/Zs/xUYK8k63rKpgD/35bq1/N+Pxj1XlNpxl+P9X5jHd/7WfxgUzuOw0hP/135r+H1O416/97lmbQ9/T37h6b9I+6pR45fv5/ml5qt8aOe5fVjrP9fAEl2pfkl4Qjgie32JySZUlUb2/ULgFOAv61mIunmzKT5WfS2uffzfSrwG6N+9lOBS3rWHz62qu5Lci/tNbaJ95yIz0vSgLGnW9Kg+RRND/cJwOKqGglX5wPfBvatqt1ohn6MnnQ5pqpaXFWH0wwt+TZNLzQ0oefpYxyyBtg7Se+/kXNohhU8fNqe5TuB71XVjJ7XE6rqyPHUr32/p456rwd5ZLAsNu0uml8geo9/tO6kGb6xZ09bdquqZ22iLnfThN5n9ey/e1WNNyRurl2Pxmk0vcK/0V4nL2rLAw/3XF9Ac539SbZ855C1ND+LTX2+dwJfHfWzf3xVvalnn4ePTfJ4mmE4a7a+aZK2Z4ZuSYPmU8BLgDfwyK/xn0AzNvu+JM8E3jTGsb8iyZPT3HbwcTRh8j6a4SYAHwP+PMlz0nhGO8ntP2h6F9+eZFqSQ4GX04ztHct/Aj9P8hdp7sE9JckBSZ47zjZ/Fnhrkn3aUPa3wD/W+O9uchlwYpL5bU/vX4/zuF9RVXcBXwben2S3NJM8n55kzKE87bcBFwIfSPLrAElmJVk4zrf8Ec3Y7InyBJpfAtYleRK/+ln8JU3Qfz1wLs0k3U3efabtHb+cZsLorknmA6/t2eWLwH5JXt1eK9OSPDfJ/j37HJnkBe1kz3cC36yqkV7uiW6/pAFl6JY0UNrx2t+gmaC2qGfTnwOvopmUdiHwj+M85U7A22h6Fu+lGd/7pva9Pkcz5vcz7XmvAJ5UVQ/QhOyX0fTkfgR4TTskZaw6b6QZ23sQ8L32mI/RTPIbj0/QDEe4tj3+/9BMVByXqvpX4IM0dzZZySbucLIVXkMzIfQW4CfA52m+JdiUv2jf95tJfgb8v4x/DPLHgflp7hIzEfcI/yDN5M67gW8CXxrZkOQ5NNfCa9qf2f+kCeBnbOGcp9AM7/ghzcTIT45saMeNv5RmDPuadp//STNpcsRnaML/vTQTgk/o2XY2cHHb/j9A0qSVqon+Zk+SJEFzy0BgVVWd1e+6SOove7olSZKkjhm6JUk7vDQPQLpvjNfxWz5akrbM4SWSJElSx+zpliRJkjpm6JYkSZI6tkM8kXLPPfesuXPn9rsakiRJmsSWLFlyd1XNHGvbDhG6586dy/DwcL+rIUmSpEksyQ82tc3hJZIkSVLHDN2SJElSxwzdkiRJUscM3ZIkSVLHDN2SJElSxwzdkiRJUscM3ZIkSVLHdoj7dD/Wrli6mnMXr2DNuvXsNWM6py+cx9ELZvW7WpIkSeoTQ/cEu2Lpas68fBnrN2wEYPW69Zx5+TIAg7ckSdIOyuElE+zcxSseDtwj1m/YyLmLV/SpRpIkSeq3TkN3kiOSrEiyMskZY2yfk+SaJEuT3JzkyJ5tz05yXZLlSZYl2aUtP65dvznJl5Ls2WUbttaadeu3qlySJEmTX2ehO8kU4MPAy4D5wHFJ5o/a7SzgsqpaABwLfKQ9dirwaeCNVfUs4FBgQ1v+IeC3q+rZwM3AKV214dHYa8b0rSqXJEnS5NdlT/chwMqqur2qHgAuBY4atU8Bu7XLuwNr2uWXAjdX1U0AVXVPVW0E0r4elyTtsWsYIKcvnMf0aVMeUTZ92hROXzivTzWSJElSv3U5kXIWcGfP+irgN0btczbw5SSnAo8DXtKW7wdUksXATODSqnpvVW1I8iZgGfAL4LvAn3bXhK03MlnSu5dIkiRpRL/vXnIccFFVvT/J84BLkhzQ1usFwHOB+4GrkywBrgXeBCwAbgf+F3Am8K7RJ05yMnAywJw5cx6DpvyXoxfMMmRLkiTpYV0OL1kN7N2zPrst63UScBlAVV0H7ALsSdMrfm1V3V1V9wNXAQcDB7X73lZV1R77W2O9eVVdUFVDVTU0c+bMiWuVJEmStJW6DN3XA/sm2SfJzjQTJReN2ucO4DCAJPvThO61wGLgwCS7tpMnXwzcQhPa5ycZSdGHA7d22AZJkiRpm3U2vKSqHkxyCk2AngJ8oqqWJzkHGK6qRcBpwIVJ3kozqfLEtgf7J0nOownuBVxVVVcCJPkb4NokG4AfACd21QZJkiRpIqTJuJPb0NBQDQ8P97sakiRJmsSSLKmqobG2+URKSZIkqWOGbkmSJKljhm5JkiSpY4ZuSZIkqWOGbkmSJKljhm5JkiSpY4ZuSZIkqWOGbkmSJKljhm5JkiSpY4ZuSZIkqWOGbkmSJKljhm5JkiSpY4ZuSZIkqWOGbkmSJKljhm5JkiSpY4ZuSZIkqWOGbkmSJKljhm5JkiSpY4ZuSZIkqWOGbkmSJKljhm5JkiSpY4ZuSZIkqWOGbkmSJKljnYbuJEckWZFkZZIzxtg+J8k1SZYmuTnJkT3bnp3kuiTLkyxLsktbvnOSC5J8J8m3k/xel22QJEmSttXUrk6cZArwYeBwYBVwfZJFVXVLz25nAZdV1flJ5gNXAXOTTAU+Dby6qm5KsgewoT3mHcCPq2q/JDsBT+qqDZIkSdJE6Cx0A4cAK6vqdoAklwJHAb2hu4Dd2uXdgTXt8kuBm6vqJoCquqfnmNcDz2zLHwLu7qoBkiRJ0kTocnjJLODOnvVVbVmvs4ETkqyi6eU+tS3fD6gki5PckOTtAElmtNvf2ZZ/LsmTO2uBJEmSNAH6PZHyOOCiqpoNHAlc0g4ZmQq8ADi+/fOVSQ5ry2cD36iqg4HrgPeNdeIkJycZTjK8du3ax6ApkiRJ0ti6DN2rgb171me3Zb1OAi4DqKrrgF2APWl6xa+tqrur6n6aXvCDgXuA+4HL2+M/15b/iqq6oKqGqmpo5syZE9MiSZIk6VHoMnRfD+ybZJ8kOwPHAotG7XMHcBhAkv1pQvdaYDFwYJJd20mVLwZuqaoCvgAc2h5/GI8cIy5JkiQNnM4mUlbVg0lOoQnQU4BPVNXyJOcAw1W1CDgNuDDJW2kmVZ7YBuufJDmPJrgXcFVVXdme+i9ohqF8kCagv66rNkiSJEkTIU3GndyGhoZqeHi439WQJEnSJJZkSVUNjbWt3xMpJUmSpEnP0C1JkiR1zNAtSZIkdczQLUmSJHXM0C1JkiR1zNAtSZIkdczQLUmSJHXM0C1JkiR1zNAtSZIkdczQLUmSJHXM0C1JkiR1zNAtSZIkdczQLUmSJHXM0C1JkiR1zNAtSZIkdczQLUmSJHXM0C1JkiR1zNAtSZIkdczQLUmSJHXM0C1JkiR1zNAtSZIkdczQLUmSJHXM0C1JkiR1rNPQneSIJCuSrExyxhjb5yS5JsnSJDcnObJn27OTXJdkeZJlSXYZdeyiJN/qsv6SJEnSRJja1YmTTAE+DBwOrAKuT7Koqm7p2e0s4LKqOj/JfOAqYG6SqcCngVdX1U1J9gA29Jz7GOC+ruouSZIkTaQue7oPAVZW1e1V9QBwKXDUqH0K2K1d3h1Y0y6/FLi5qm4CqKp7qmojQJLHA28D3tVh3SVJkqQJ02XongXc2bO+qi3rdTZwQpJVNL3cp7bl+wGVZHGSG5K8veeYdwLvB+7f3JsnOTnJcJLhtWvXbkMzJEmSpG3T74mUxwEXVdVs4EjgkiQ70Qx7eQFwfPvnK5McluQg4OlV9c9bOnFVXVBVQ1U1NHPmzA6bIEmSJG1eZ2O6gdXA3j3rs9uyXicBRwBU1XXtZMk9aXrFr62quwGSXAUcTDOOeyjJ99u6/3qSf6+qQztshyRJkrRNuuzpvh7YN8k+SXYGjgUWjdrnDuAwgCT7A7sAa4HFwIFJdm0nVb4YuKWqzq+qvapqLk0P+HcM3JIkSRp0nfV0V9WDSU6hCdBTgE9U1fIk5wDDVbUIOA24MMlbaSZVnlhVBfwkyXk0wb2Aq6rqyq7qKkmSJHUpTcad3IaGhmp4eLjf1ZAkSdIklmRJVQ2Nta3fEyklSZKkSc/QLUmSJHXM0C1JkiR1zNAtSZIkdczQLUmSJHXM0C1JkiR1rMsnUkoAXLF0NecuXsGadevZa8Z0Tl84j6MXzOp3tSRJkh4zhm516oqlqznz8mWs37ARgNXr1nPm5csADN6SJGmH4fASdercxSseDtwj1m/YyLmLV/SpRpIkSY89Q7c6tWbd+q0qlyRJmowM3erUXjOmb1W5JEnSZGToVqdOXziP6dOmPKJs+rQpnL5wXp9qJEmS9NhzIqU6NTJZ0ruXSJKkHZmhW507esEsQ7YkSdqhObxEkiRJ6pihW5IkSeqYoVuSJEnqmKFbkiRJ6pihW5IkSeqYoVuSJEnqmKFbkiRJ6pihW5IkSepYp6E7yRFJViRZmeSMMbbPSXJNkqVJbk5yZM+2Zye5LsnyJMuS7JJk1yRXJvl2W/6eLusvSZIkTYTOQneSKcCHgZcB84HjkswftdtZwGVVtQA4FvhIe+xU4NPAG6vqWcChwIb2mPdV1TOBBcDzk7ysqzZIkiRJE6HLnu5DgJVVdXtVPQBcChw1ap8CdmuXdwfWtMsvBW6uqpsAquqeqtpYVfdX1TVt2QPADcDsDtsgSZIkbbMuQ/cs4M6e9VVtWa+zgROSrAKuAk5ty/cDKsniJDckefvokyeZAbwcuHqiKy5JkiRNpH5PpDwOuKiqZgNHApck2QmYCrwAOL7985VJDhs5qB1+8lng76rq9rFOnOTkJMNJhteuXdt1OyRJkqRN6jJ0rwb27lmf3Zb1Ogm4DKCqrgN2Afak6RW/tqrurqr7aXrBD+457gLgu1X1wU29eVVdUFVDVTU0c+bMbW6MJEmS9Gh1GbqvB/ZNsk+SnWkmSi4atc8dwGEASfanCd1rgcXAge3dSqYCLwZuafd7F83477d0WHdJkiRpwnQWuqvqQeAUmgB9K81dSpYnOSfJK9rdTgPekOQmmuEiJ1bjJ8B5NMH9RuCGqroyyWzgHTR3Q7khyY1J/qirNkiSJEkTIVXV7zp0bmhoqIaHh/tdDUmSJE1iSZZU1dBY2/o9kVKSJEma9AzdkiRJUscM3ZIkSVLHDN2SJElSxwzdkiRJUscM3ZIkSVLHDN2SJElSxwzdkiRJUsfGHbqTTE8yr8vKSJIkSZPRuEJ3kpfTPI79S+36QUkWdVkxSZIkabIYb0/32cAhwDqAqroR2KejOkmSJEmTynhD94aq+umosproykiSJEmT0dRx7rc8yauAKUn2Bd4MfKO7akmSJEmTx3h7uk8FngX8EvgM8FPgLV1VSpIkSZpMttjTnWQKcGVV/Tbwju6rJEmSJE0uW+zprqqNwENJdn8M6iNJkiRNOuMd030fsCzJV4BfjBRW1Zs7qZUkSZI0iYw3dF/eviRJkiRtpXGF7qq6OMnOwH5t0Yqq2tBdtSRJ0ogrlq7m3MUrWLNuPXvNmM7pC+dx9IJZ/a6WpK0wrtCd5FDgYuD7QIC9k7y2qq7trmqSJOmKpas58/JlrN+wEYDV69Zz5uXLAAze0nZkvLcMfD/w0qp6cVW9CFgIfKC7akmSJIBzF694OHCPWL9hI+cuXtGnGkl6NMYbuqdV1cN/u6vqO8C0bqokSZJGrFm3fqvKJQ2m8U6kHE7yMeDT7frxwHA3VZIkSSP2mjGd1WME7L1mTO9DbSQ9WuPt6X4TcAvN49/f3C6/aUsHJTkiyYokK5OcMcb2OUmuSbI0yc1JjuzZ9uwk1yVZnmRZkl3a8ue06yuT/F2SjLMNkiRtd05fOI/p06Y8omz6tCmcvnBen2ok6dEYb0/3VOBDVXUePPyUyl/b3AHtPh8GDgdWAdcnWVRVt/TsdhZwWVWdn2Q+cBUwN8lUml71V1fVTUn2AEbulnI+8AbgP9r9jwD+dZztkCRpuzIyWdK7l0jbt/GG7quBl9A8JAdgOvBl4Lc2c8whwMqquh0gyaXAUTS95CMK2K1d3h1Y0y6/FLi5qm4CqKp72nM8Bditqr7Zrn8KOBpDtyRpEjt6wSxDtrSdG+/wkl2qaiRw0y7vuoVjZgF39qyvast6nQ2ckGQVTa/1qW35fkAlWZzkhiRv7znnqi2cU5IkSRoo4+3p/kWSg6vqBoAkQ8BETJs+Drioqt6f5HnAJUkOaOv1AuC5wP3A1UmWAD8d74mTnAycDDBnzpwJqKq07XzAhSRJO6bxhu4/Az6XZGT4x1OAP9zCMauBvXvWZ7dlvU6iGZNNVV3XTpbck6YH+9qquhsgyVXAwTTjvGdv4Zy057sAuABgaGiotlBXqXM+4EKSpB3XeIeX7AMsoLljyVeAFTTjsTfnemDfJPu0j5A/Flg0ap87gMMAkuwP7AKsBRYDBybZtZ1U+WLglqq6C/hZkt9s71ryGuBfxtkGqa98wIUkSTuu8Ybu/1FVPwNmAL8NfITmLiKbVFUPAqfQBOhbae5SsjzJOUle0e52GvCGJDcBnwVOrMZPgPNogvuNwA1VdWV7zJ8AHwNWArfhJEptJ3zAhSRJO67xDi8Z6Z77b8CFVXVlkndt6aCquopmgmRv2V/1LN8CPH8Tx36a/3oYT2/5MHDAOOstDQwfcCFJ0o5rvD3dq5P8Pc047quS/NpWHCsJH3AhSdKObLzB+Q9ohoksrKp1wJOA0zurlTQJHb1gFu8+5kBmzZhOgFkzpvPuYw50EqUkSTuAVE3+G3sMDQ3V8PBwv6shSZKkSSzJkqoaGmubQ0QkSZKkjhm6JUmSpI4ZuiVJkqSOGbolSZKkjhm6JUmSpI4ZuiVJkqSOGbolSZKkjhm6JUmSpI4ZuiVJkqSOGbolSZKkjhm6JUmSpI4ZuiVJkqSOGbolSZKkjhm6JUmSpI5N7XcFJEmStsYVS1dz7uIVrFm3nr1mTOf0hfM4esGsfldL2ixDtyRJ2m5csXQ1Z16+jPUbNgKwet16zrx8GYDBWwPN4SWSJGm7ce7iFQ8H7hHrN2zk3MUr+lQjaXwM3ZIkabuxZt36rSqXBoWhW5IkbTf2mjF9q8qlQWHoliRJ243TF85j+rQpjyibPm0Kpy+c16caSePTaehOckSSFUlWJjljjO1zklyTZGmSm5Mc2ZbPTbI+yY3t66M9xxyXZFm7/5eS7NllGyRJ0uA4esEs3n3MgcyaMZ0As2ZM593HHOgkSg28VFU3J06mAN8BDgdWAdcDx1XVLT37XAAsrarzk8wHrqqquUnmAl+sqgNGnXMqsAaYX1V3J3kvcH9Vnb25ugwNDdXw8PDENU6SJEkaJcmSqhoaa1uXPd2HACur6vaqegC4FDhq1D4F7NYu704TqDcn7etxSdIeu6VjJEmSpL7qMnTPAu7sWV/VlvU6GzghySrgKuDUnm37tMNOvprkhQBVtQF4E7CMtscb+Hg31ZckSZImRr8nUh4HXFRVs4EjgUuS7ATcBcypqgXA24DPJNktyTSa0L0A2Au4GThzrBMnOTnJcJLhtWvXPhZtkSRJksbUZeheDezdsz67Let1EnAZQFVdB+wC7FlVv6yqe9ryJcBtwH7AQW3ZbdUMRr8M+K2x3ryqLqiqoaoamjlz5sS1SpIkSdpKXYbu64F9k+yTZGfgWGDRqH3uAA4DSLI/Tehem2RmOxGTJE8D9gVupwnt85OMpOjDgVs7bIMkSZK0zaZ2deKqejDJKcBiYArwiapanuQcYLiqFgGnARcmeSvNpMoTq6qSvAg4J8kG4CHgjVV1L0CSvwGubbf9ADixqzZIkiRJE6GzWwYOEm8ZKEmSpK7165aBkiRJkjB0S5IkSZ0zdEuSJEkdM3RLkiRJHTN0S5IkSR0zdEuSJEkdM3RLkiRJHTN0S5IkSR0zdEuSJEkdM3RLkiRJHTN0S5IkSR0zdEuSJEkdM3RLkiRJHTN0S5IkSR0zdEuSJEkdM3RLkiRJHTN0S5IkSR0zdEuSJEkdM3RLkiRJHTN0S5IkSR0zdEuSJEkdM3RLkiRJHTN0S5IkSR3rNHQnOSLJiiQrk5wxxvY5Sa5JsjTJzUmObMvnJlmf5Mb29dGeY3ZOckGS7yT5dpLf67INkiRJ0raa2tWJk0wBPgwcDqwCrk+yqKpu6dntLOCyqjo/yXzgKmBuu+22qjpojFO/A/hxVe2XZCfgSV21QZIkSZoInYVu4BBgZVXdDpDkUuAooDd0F7Bbu7w7sGYc53098EyAqnoIuHuiKixJkiR1ocvhJbOAO3vWV7Vlvc4GTkiyiqaX+9Sebfu0w06+muSFAElmtNvemeSGJJ9L8uRuqi9JkiRNjH5PpDwOuKiqZgNHApe0Q0buAuZU1QLgbcBnkuxG0zM/G/hGVR0MXAe8b6wTJzk5yXCS4bVr1z4WbZEkSZLG1GXoXg3s3bM+uy3rdRJwGUBVXQfsAuxZVb+sqnva8iXAbcB+wD3A/cDl7fGfAw4e682r6oKqGqqqoZkzZ05MiyRJkqRHocvQfT2wb5J9kuwMHAssGrXPHcBhAEn2pwnda5PMbCdikuRpwL7A7VVVwBeAQ9vjD+ORY8QlSZKkgdPZRMqqejDJKcBiYArwiapanuQcYLiqFgGnARcmeSvNpMoTq6qSvAg4J8kG4CHgjVV1b3vqv6AZhvJBYC3wuq7aIEmSJE2ENJ3Hk9vQ0FANDw/3uxqSJEmaxJIsqaqhsbb1eyKlJEmSNOkZuiVJkqSOGbolSZKkjhm6JUmSpI4ZuiVJkqSOGbolSZKkjhm6JUmSpI4ZuiVJkqSOGbolSZKkjhm6JUmSpI4ZuiVJkqSOGbolSZKkjhm6JUmSpI4ZuiVJkqSOTe13BSRJGu2Kpas5d/EK1qxbz14zpnP6wnkcvWBWv6slSY+aoVuSNFCuWLqaMy9fxvoNGwFYvW49Z16+DMDgLWm7ZeiWJA2UcxeveDhwj1i/YSPnLl5h6Ja0WYP8LZmhW5I0UNasW79V5ZIEg/8tmRMpJUkDZa8Z07eqXJJg89+SDQJDtyRpoJy+cB7Tp015RNn0aVM4feG8PtVI0vZg0L8lM3RLkgbK0Qtm8e5jDmTWjOkEmDVjOu8+5sCB+HpY0uAa9G/JHNMtSRo4Ry+YZciWtFVOXzjvEWO6YYiXIgIAAArGSURBVLC+JTN0S9KAGORZ95I06Eb+vRzUf0c7Dd1JjgA+BEwBPlZV7xm1fQ5wMTCj3eeMqroqyVzgVmBk5Ps3q+qNo45dBDytqg7osg2S9FgY9Fn3krQ9GORvyTob051kCvBh4GXAfOC4JPNH7XYWcFlVLQCOBT7Ss+22qjqofY0O3McA93VVd0l6rA36rHtJ0rbpciLlIcDKqrq9qh4ALgWOGrVPAbu1y7sDa7Z00iSPB94GvGsC6ypJfTXos+4lSdumy9A9C7izZ31VW9brbOCEJKuAq4BTe7btk2Rpkq8meWFP+TuB9wP3T3yVJak/Bn3WvSRp2/T7loHHARdV1WzgSOCSJDsBdwFz2mEnbwM+k2S3JAcBT6+qf97SiZOcnGQ4yfDatWu7bIMkbTPvTS1Jk1uXoXs1sHfP+uy2rNdJwGUAVXUdsAuwZ1X9sqruacuXALcB+wHPA4aSfB/4GrBfkn8f682r6oKqGqqqoZkzZ05YoySpC96bWpImty7vXnI9sG+SfWjC9rHAq0btcwdwGHBRkv1pQvfaJDOBe6tqY5KnAfsCt1fVMHA+QHuHky9W1aEdtkGSHjODPOtekrRtOgvdVfVgklOAxTS3A/xEVS1Pcg4wXFWLgNOAC5O8lWZS5YlVVUleBJyTZAPwEPDGqrq3q7pKkiRJXUpV9bsOnRsaGqrh4eF+V0OSJEmTWJIlVTU01rZ+T6SUJEmSJj0fAy+pb3zsuSRpR2HoltQXPvZckrQjcXiJpL7wseeSpB2JoVtSX/jYc0nSjsTQLakvfOy5JGlHYuiW1Bc+9lyStCNxIqWkvhiZLOndSyRJOwJDt6S+8bHnkqQdhcNLJEmSpI4ZuiVJkqSOGbolSZKkjhm6JUmSpI45kVKSJGk7dcXS1d4Fajth6JYkSdoOXbF0NWdevoz1GzYCsHrdes68fBmAwXsAObxEkiRpO3Tu4hUPB+4R6zds5NzFK/pUI22OoVuSJGk7tGbd+q0qV38ZuiVJkrZDe82YvlXl6i9DtyRJ0nbo9IXzmD5tyiPKpk+bwukL5/WpRtocJ1JKkiRth0YmS3r3ku2DoVuSJGk7dfSCWYbs7YTDSyRJkqSOGbolSZKkjnUaupMckWRFkpVJzhhj+5wk1yRZmuTmJEe25XOTrE9yY/v6aFu+a5Irk3w7yfIk7+my/pIkSdJE6GxMd5IpwIeBw4FVwPVJFlXVLT27nQVcVlXnJ5kPXAXMbbfdVlUHjXHq91XVNUl2Bq5O8rKq+teu2iFJkiRtqy57ug8BVlbV7VX1AHApcNSofQrYrV3eHVizuRNW1f1VdU27/ABwAzB7QmstSZIkTbAuQ/cs4M6e9VVtWa+zgROSrKLp5T61Z9s+7bCTryZ54eiTJ5kBvBy4ekJrLUmSJE2wfk+kPA64qKpmA0cClyTZCbgLmFNVC4C3AZ9JMtIjTpKpwGeBv6uq28c6cZKTkwwnGV67dm3nDZEkSZI2pcv7dK8G9u5Zn92W9ToJOAKgqq5LsguwZ1X9GPhlW74kyW3AfsBwe9wFwHer6oObevOquqDdjyRrk/xg25ukbbQncHe/K6GB5LWhTfHa0OZ4fWhT+nVtPHVTG7oM3dcD+ybZhyZsHwu8atQ+dwCHARcl2R/YBVibZCZwb1VtTPI0YF/gdoAk76IZ//1H461IVc3c1sZo2yUZrqqhftdDg8drQ5vitaHN8frQpgzitdHZ8JKqehA4BVgM3Epzl5LlSc5J8op2t9OANyS5iWa4yIlVVcCLgJuT3Ah8HnhjVd2bZDbwDmA+cEN7O8Fxh29JkiSpH9JkXKl7g/hbpwaD14Y2xWtDm+P1oU0ZxGuj3xMptWO5oN8V0MDy2tCmeG1oc7w+tCkDd23Y0y1JkiR1zJ5uSZIkqWOGbnUqyd5JrklyS5LlSf6s33XSYEkypX0Q1hf7XRcNliQzknw+ybeT3Jrkef2ukwZDkre2/6d8K8ln21sOaweV5BNJfpzkWz1lT0rylSTfbf98Yj/rCIZude9B4LSqmg/8JvCnSeb3uU4aLH9Gc4cjabQPAV+qqmcC/zdeJwKSzALeDAxV1QHAFJrbEmvHdRHtc196nAFcXVX70jy9/IzHulKjGbrVqaq6q6puaJd/TvOf5qz+1kqDor0N6H8DPtbvumiwJNmd5vaxHweoqgeqal1/a6UBMhWY3j6heldgTZ/roz6qqmuBe0cVHwVc3C5fDBz9mFZqDIZuPWaSzAUWAP/R35pogHwQeDvwUL8rooGzD7AW+GQ7/OhjSR7X70qp/6pqNfA+mgfs3QX8tKq+3N9aaQA9uaruapd/CDy5n5UBQ7ceI0keD/wT8Jaq+lm/66P+S/K7wI+rakm/66KBNBU4GDi/qhYAv2AAvh5W/7Vjc4+i+cVsL+BxSU7ob600yNoHL/b9dn2GbnUuyTSawP0PVXV5v+ujgfF84BVJvg9cCvxOkk/3t0oaIKuAVVU18s3Y52lCuPQS4HtVtbaqNgCXA7/V5zpp8PwoyVMA2j9/3Of6GLrVrSShGZN5a1Wd1+/6aHBU1ZlVNbuq5tJMgvq3qrK3SgBU1Q+BO5PMa4sOA27pY5U0OO4AfjPJru3/MYfhJFv9qkXAa9vl1wL/0se6AIZude/5wKtpejFvbF9H9rtSkrYLpwL/kORm4CDgb/tcHw2A9tuPzwM3AMtosszAPX1Qj50knwWuA+YlWZXkJOA9wOFJvkvz7ch7+llH8ImUkiRJUufs6ZYkSZI6ZuiWJEmSOmboliRJkjpm6JYkSZI6ZuiWJEmSOmboliRJkjpm6JYkbVGS7yfZ81Eee2KSvSbiXJK0vTJ0S5K6diKw15Z2kqTJzNAtSduRJHOTfDvJRUm+k+QfkrwkydeTfDfJIe3ruiRLk3xj5FHqSd6a5BPt8oFJvpVk1028zx5JvpxkeZKPAenZdkKS/2yfMPv3Saa05fcl+UB7zNVJZib5fWCI5smSNyaZ3p7m1CQ3JFmW5JldfmaSNAgM3ZK0/XkG8H7gme3rVcALgD8H/hL4NvDCqloA/BX/9fj0DwHPSPJK4JPAH1fV/Zt4j78GvlZVzwL+GZgDkGR/4A+B51fVQcBG4Pj2mMcBw+0xXwX+uqo+DwwDx1fVQVW1vt337qo6GDi/rbckTWpT+10BSdJW+15VLQNIshy4uqoqyTJgLrA7cHGSfYECpgFU1UNJTgRuBv6+qr6+mfd4EXBMe9yVSX7Slh8GPAe4PgnAdODH7baHgH9slz8NXL6Z849sWzLyPpI0mRm6JWn788ue5Yd61h+i+Xf9ncA1VfXKJHOBf+/Zf1/gPh79GOsAF1fVmePYtzazbaTOG/H/Ikk7AIeXSNLkszuwul0+caQwye7A39H0Yu/RjrfelGtphq2Q5GXAE9vyq4HfT/Lr7bYnJXlqu20nYOScrwK+1i7/HHjCNrRHkrZ7hm5JmnzeC7w7yVIe2Yv8AeDDVfUd4CTgPSPheQx/A7yoHb5yDHAHQFXdApwFfDnJzcBXgKe0x/wCOCTJt4DfAc5pyy8CPjpqIqUk7VBStblv/yRJGp8k91XV4/tdD0kaRPZ0S5IkSR2zp1uSdmBJXgf82ajir1fVn/ajPpI0WRm6JUmSpI45vESSJEnqmKFbkiRJ6pihW5IkSeqYoVuSJEnqmKFbkiRJ6tj/D9PE5usKLb5WAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Lp9_Lr62GmKt",
        "outputId": "eb37839e-0142-4e47-8d71-ba6f90c17c6e"
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.scatter(list(split_score.keys()), list(split_score.values()))\n",
        "plt.xlabel('min_split')\n",
        "plt.ylabel('score')\n",
        "plt.title('Val score for different min_split')\n",
        "plt.show()\n",
        "plt.show()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAFOCAYAAABaLaGCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5xddX3n8debJJTxB6RKZE0CBBVSUSvRLLW1Wi21QWola7sKylpaWldbbf0Vl1h3pXS7dZvW1q5WC2pRKyraNMVKja26aittmRgkgsYCCmRCJaJR0VkM4bN/3DP0Mp0kM2S+3DuT1/PxuI/c8z3nfM/nnEzgPd/7PeemqpAkSZLUzmGDLkCSJEma7wzdkiRJUmOGbkmSJKkxQ7ckSZLUmKFbkiRJaszQLUmSJDVm6JY0ryWpJI8adB3TkWQkyYeTfCvJBxsd457rkeRtSf5737qXJPlakjuSPDTJk5P8S7e8tkU995ckT0myfUDHflqSHX3L1yZ52iBqkTQ4CwddgCTtT5KPAv9cVf9jUvuZwJ8Cy6vqroEUN/t+HjgGeOj9cU5V9eKJ90kWAW8EnlRVn+/aLgTeXFVval3LZEkuAXZU1etmo7+q+gywcjb6OlhV9ZiJ90kuAB5VVecMriJJ9wdHuiUNu3cB5yTJpPb/Arx3mAN3kgUz3OV44Mv35ZySHOwgyjHAEcC1k+q5durNm9cjSfOKoVvSsNsEPBR4ykRDkh8EngW8O8mpSa5MsjvJrUnenOTw6XSc5NwkNyb5TpKvJHlB37pfSfLFbt11SZ7QtT86yf/tjndtkmf37XNJkrcmuSLJd4GnJ1ma5C+S7OqO8ev7qOW3gP8BPK+bznFeksOSvC7JTUluS/LuJEd126/opoqcl+Rm4BP76Hddd112JvmlSesuSfI/k5wETEy92J3kE0luAB4BfLir5weSHJXkHV1/Y92+C/qu5T8k+cMktwMXdPv8fpKbu2krb0sy0m3/tCQ7kryqO7dbk/xit+5FwAuA13TH/vA+zq2S/Go3BeY7SX47ySOTfDbJt5NcNvGzMMUUj68meXWSa7rpPB9IcsSUPyj/ts/RSf66+7v/RpLPJDmsr7/13c/KN5P82b7667b9qSSnA6/t+zv//P6OL2luM3RLGmpVNQ5cBrywr/m5wJe6aRB7gVcARwM/CpwG/OqB+k3yQOCPgWdW1YOBHwOu7tb9Z+CC7phHAs8Gbu+mYHwY+BjwMOBlwHuT9E9beD7wO8CDgc92238eWNbV9vIka6Y4z9cD/wv4QFU9qKreAZzbvZ5OLwA/CHjzpF1/Ang08O/67ELdq4FnACcCPzXVtaiqLwMTUx4WV9VPVtUjgZuBn+3quRO4BLgLeBSwCvhp4Jf7uvoR4EZ6o+a/A7wBOAk4pdtnGb1fLCb8B+Corv084C1JfrCqLgLeC/xed+yfnaruzhrgicCTgNcAFwHnAMcCjwXO3s++zwVOB04Afpjetd6fVwE7gCXdOb4WqL71L+jqeWR33vudGlNVH+Xef+ePP8DxJc1hhm5Jc8G7gJ/vGzl8YddGVW2pqn+sqruq6qv05nn/xDT7vRt4bJKRqrq1qiamUvwyvcB3VfVcX1U30Qt2DwLeUFXfr6pPAH/NvYPdX1XVP1TV3cDjgCVVdWG3/Y3AxcBZ06zvBcAbq+rGqroDWA+cNWnqxgVV9d3ul5PJngv8WVV9oaq+S+8XifskyTHAGcDLu+PdBvzhpHPZWVX/p5se8/+AFwGvqKpvVNV36AXM/u33ABdW1Z6qugK4g5nPu/69qvp293f3BeBj3fX6FvA39H452Jc/rqqdVfUNer8cnXKAY+0BHg4c39X8marqD91vrqpbuv5+h/0HfkmHGEO3pKFXVX8PfB1Ym+SRwKnApQBJTuo+8v/XJN+mF+yOnkaf3wWeB7wYuDXJR5L8ULf6WOCGKXZbCtzSBeoJN9EbqZ1wS9/744Gl3XSE3Ul20xsdPebAZ33P8W6adKyFk/a/hX1bOmn9TfvacBqOBxbRu1YT5/Kn9Eb8p6plCfAAYEvf9h/t2ifcPmn++vfo/VIzE1/rez8+xfL++vvXGR57A3A98LH0piWdP2n95Gu99AD9STqEGLolzRXvpjfCfQ6wuaomwtVbgS8BJ1bVkfRC7eSbLqdUVZur6hn0Ri+/RG8UGnrh6ZFT7LITOHZiHm/nOGCsv9u+97cAX6mqxX2vB1fVGdOprzve8ZOOdRf3DpbFvt1K7xeI/v3vq1uAO4Gj+87lyP4ncUyq5ev0Qu9j+rY/qqqmG6r3d14DUVXfqapXVdUj6E05emWS0/o2mXytd06n29msUdLwMnRLmiveTW9O8q/QTS3pPBj4NnBHN1L9kul0luSYJGd2c7vvpDe1YWIE++3Aq5M8MT2PSnI88E/0RkRfk2RRes9a/lng/fs4zD8D30ny39J7BveCJI9N8h+nec7vA16R5IQkD+Lf5v9O9+kmlwHnJjk5yQOA109zv3+nqm6lN5f9D5Icmd5Nno9MMuVUnu7TgIuBP0zyMIAky6aaz74PX6M3j31oJHlW97MQ4Fv07ifo/9Tj15IsT/IQ4DeBD0yj268BKyb9IidpHvIfuaQ5oZuv/VnggcDlfateTe/mxe/QC3nTCTrQ++/fK+mNRn6D3jzwl3TH+iC9ObmXdv1uAh5SVd+nF7KfSW8k90+AF1bVl/ZR8156T1k5BfhKt8/b6d08OB3vBN4DfLrb///Ru3lzWqrqb4A/ovdkk+vZxxNOZuCFwOHAdcA3gQ/R+5RgX/5bd9x/7Kb+/B3Tn7P9DuDkbmrKpvte8qw6kd453AFcCfxJVX2yb/2l9H4xuZHe9KT/OY0+J74E6fYkn5vFWiUNmdz7HhBJkjRTSb4K/HJV/d2ga5E0nBzpliRJkhozdEuS1Eny2u6Laia//mbQtUma25xeIkmSJDXmSLckSZLUmKFbkiRJamzhgTeZ+44++uhasWLFoMuQJEnSPLZly5avV9WSqdYdEqF7xYoVjI6ODroMSZIkzWNJbtrXOqeXSJIkSY0ZuiVJkqTGDN2SJElSY4ZuSZIkqTFDtyRJktSYoVuSJElqzNAtSZIkNXZIPKdb0qFr09YxNmzezs7d4yxdPMK6NStZu2rZoMuSJB1iDN2S5q1NW8dYv3Eb43v2AjC2e5z1G7cBGLwlSfcrp5dImrc2bN5+T+CeML5nLxs2bx9QRZKkQ5WhW9K8tXP3+IzaJUlqxdAtad5aunhkRu2SJLVi6JY0b61bs5KRRQvu1TayaAHr1qwcUEWSpEOVN1JKmrcmbpb06SWSpEEzdEua19auWmbIliQNnNNLJEmSpMYM3ZIkSVJjhm5JkiSpMed0S5J0EDZtHfNmXUkHZOiWJOk+2rR1jPUbt93zzadju8dZv3EbgMFb0r04vUSSpPtow+bt9wTuCeN79rJh8/YBVSRpWBm6JUm6j3buHp9Ru6RDl6FbkqT7aOnikRm1Szp0GbolSbqP1q1ZyciiBfdqG1m0gHVrVg6oIknDyhspJUm6jyZulvTpJZIOxNAtSdJBWLtqmSFb0gE5vUSSJElqzNAtSZIkNWboliRJkhozdEuSJEmNGbolSZKkxgzdkiRJUmOGbkmSJKkxQ7ckSZLUmKFbkiRJaszQLUmSJDVm6JYkSZIaM3RLkiRJjRm6JUmSpMaahu4kpyfZnuT6JOdPsf64JJ9MsjXJNUnO6Fv3w0muTHJtkm1Jjujan9gtX5/kj5Ok5TlIkiRJB6tZ6E6yAHgL8EzgZODsJCdP2ux1wGVVtQo4C/iTbt+FwJ8DL66qxwBPA/Z0+7wV+BXgxO51eqtzkCRJkmZDy5HuU4Hrq+rGqvo+8H7gzEnbFHBk9/4oYGf3/qeBa6rq8wBVdXtV7U3ycODIqvrHqirg3cDahucgSZIkHbSWoXsZcEvf8o6urd8FwDlJdgBXAC/r2k8CKsnmJJ9L8pq+PnccoE9JkiRpqAz6RsqzgUuqajlwBvCeJIcBC4EfB17Q/fmfkpw2k46TvCjJaJLRXbt2zXbdkiRJ0rS1DN1jwLF9y8u7tn7nAZcBVNWVwBHA0fRGsD9dVV+vqu/RGwV/Qrf/8gP0SdffRVW1uqpWL1myZBZOR5IkSbpvWobuq4ATk5yQ5HB6N0pePmmbm4HTAJI8ml7o3gVsBh6X5AHdTZU/AVxXVbcC307ypO6pJS8E/qrhOUiSJEkHbWGrjqvqriQvpRegFwDvrKprk1wIjFbV5cCrgIuTvILeTZXndjdIfjPJG+kF9wKuqKqPdF3/KnAJMAL8TfeSJEmShlZ6GXd+W716dY2Ojg66DEmSJM1jSbZU1eqp1g36RkpJkiRp3jN0S5IkSY0ZuiVJkqTGDN2SJElSY4ZuSZIkqTFDtyRJktSYoVuSJElqzNAtSZIkNWboliRJkhozdEuSJEmNGbolSZKkxgzdkiRJUmOGbkmSJKkxQ7ckSZLUmKFbkiRJaszQLUmSJDVm6JYkSZIaM3RLkiRJjRm6JUmSpMYM3ZIkSVJjhm5JkiSpMUO3JEmS1JihW5IkSWrM0C1JkiQ1ZuiWJEmSGjN0S5IkSY0ZuiVJkqTGDN2SJElSY4ZuSZIkqTFDtyRJktSYoVuSJElqzNAtSZIkNWboliRJkhozdEuSJEmNGbolSZKkxgzdkiRJUmOGbkmSJKkxQ7ckSZLUmKFbkiRJaszQLUmSJDVm6JYkSZIaM3RLkiRJjRm6JUmSpMYM3ZIkSVJjhm5JkiSpMUO3JEmS1JihW5IkSWqsaehOcnqS7UmuT3L+FOuPS/LJJFuTXJPkjK59RZLxJFd3r7f17fO8bttrk/zvlvVLkiRJs2Fhq46TLADeAjwD2AFcleTyqrqub7PXAZdV1VuTnAxcAazo1t1QVadM6vOhwAbgiVW1K8m7kpxWVR9vdR6SJEnSwWo50n0qcH1V3VhV3wfeD5w5aZsCjuzeHwXsPECfjwD+pap2dct/B/zcLNUrSZIkNdEydC8Dbulb3tG19bsAOCfJDnqj3C/rW3dCN+3kU0me0rVdD6zspp8sBNYCxzapXpIkSZolg76R8mzgkqpaDpwBvCfJYcCtwHFVtQp4JXBpkiOr6pvAS4APAJ8BvgrsnarjJC9KMppkdNeuXVNtIkmSJN0vWobuMe49Cr28a+t3HnAZQFVdCRwBHF1Vd1bV7V37FuAG4KRu+cNV9SNV9aPAduDLUx28qi6qqtVVtXrJkiWzeFqSJEnSzLQM3VcBJyY5IcnhwFnA5ZO2uRk4DSDJo+mF7l1JlnQ3YpLkEcCJwI3d8sO6P38Q+FXg7Q3PQZIkSTpozZ5eUlV3JXkpsBlYALyzqq5NciEwWlWXA68CLk7yCno3VZ5bVZXkqcCFSfYAdwMvrqpvdF2/Kcnju/cXVtWUI92SJEnSsEhVDbqG5lavXl2jo6ODLkOSJEnzWJItVbV6qnWDvpFSkiRJmvcM3ZIkSVJjhm5JkiSpMUO3JEmS1JihW5IkSWqs2SMDD2Wbto6xYfN2du4eZ+niEdatWcnaVcsGXZYkSZIGxNA9yzZtHWP9xm2M7+l9O/3Y7nHWb9wGYPCWJEk6RDm9ZJZt2Lz9nsA9YXzPXjZs3j6giiRJkjRohu5ZtnP3+IzaJUmSNP8ZumfZ0sUjM2qXJEnS/GfonmXr1qxkZNGCe7WNLFrAujUrB1SRJEmSBs0bKWfZxM2SPr1EkiRJEwzdDaxdtcyQLUmSpHs4vUSSJElqzNAtSZIkNWboliRJkhozdEuSJEmNGbolSZKkxqYdupOMJPFh05IkSdIMTSt0J/lZ4Grgo93yKUkub1mYJEmSNF9Md6T7AuBUYDdAVV0NnNCoJkmSJGlemW7o3lNV35rUVrNdjCRJkjQfTfcbKa9N8nxgQZITgV8HPtuuLEmSJGn+mO5I98uAxwB3ApcC3wJe3qooSZIkaT454Eh3kgXAR6rq6cBvti9JkiRJml8OONJdVXuBu5McdT/UI0mSJM07053TfQewLcnfAt+daKyqX29SlSRJkjSPTDd0b+xekiRJkmZoWqG7qt6V5HDgpK5pe1XtaVeWJEmSNH9MK3QneRrwLuCrQIBjk/xCVX26XWmSJEnS/DDd6SV/APx0VW0HSHIS8D7gia0KkyRJkuaL6T6ne9FE4Aaoqi8Di9qUJEmSJM0v0x3pHk3yduDPu+UXAKNtSpIkSZLml+mG7pcAv0bv698BPgP8SZOKJEmSpHlmuqF7IfCmqnoj3PMtlT/QrCpJkiRpHpnunO6PAyN9yyPA381+OZIkSdL8M93QfURV3TGx0L1/QJuSJEmSpPlluqH7u0meMLGQZDUw3qYkSZIkaX6Z7pzu3wA+mGRnt/xw4HltSpIkSZLml+mG7hOAVcBxwHOAHwGqVVGSJEnSfDLd6SX/vaq+DSwGnk7vcYFvbVaVJEmSNI9MN3Tv7f78GeDiqvoIcHibkiRJkqT5ZbqheyzJn9Kbx31Fkh+Ywb6SJEnSIW26wfm5wGZgTVXtBh4CrGtWlSRJkjSPTOtGyqr6HrCxb/lW4NZWRUmSJEnziVNEJEmSpMYM3ZIkSVJjTUN3ktOTbE9yfZLzp1h/XJJPJtma5JokZ3TtK5KMJ7m6e72tb5+zk2zrtv9okqNbnoMkSZJ0sJqF7iQLgLcAzwROBs5OcvKkzV4HXFZVq4Cz6D3/e8INVXVK93px1+dC4E3A06vqh4FrgJe2OgdJkiRpNrQc6T4VuL6qbqyq7wPvB86ctE0BR3bvjwJ2sn/pXg9Mkm7fA+0jSZIkDVTL0L0MuKVveUfX1u8C4JwkO4ArgJf1rTuhm3byqSRPAaiqPcBLgG30wvbJwDvalC9JkiTNjkHfSHk2cElVLQfOAN6T5DB6jyM8rpt28krg0iRHJllEL3SvApbSm16yfqqOk7woyWiS0V27dt0f5yJJkiRNqWXoHgOO7Vte3rX1Ow+4DKCqrgSOAI6uqjur6vaufQtwA3AScErXdkNVVbfvj0118Kq6qKpWV9XqJUuWzN5ZSZIkSTPUMnRfBZyY5IQkh9O7UfLySdvcDJwGkOTR9EL3riRLuhsxSfII4ETgRnqh/eQkEyn6GcAXG56DJEmSdNCm9Y2U90VV3ZXkpfS+Pn4B8M6qujbJhcBoVV0OvAq4OMkr6N1UeW5VVZKnAhcm2QPcDby4qr4BkOS3gE93624Czm11DpIkSdJsSG+Wxvy2evXqGh0dHXQZkiRJmseSbKmq1VOtG/SNlJIkSdK8Z+iWJEmSGjN0S5IkSY0ZuiVJkqTGDN2SJElSY4ZuSZIkqTFDtyRJktSYoVuSJElqzNAtSZIkNWboliRJkhozdEuSJEmNGbolSZKkxgzdkiRJUmOGbkmSJKkxQ7ckSZLUmKFbkiRJaszQLUmSJDVm6JYkSZIaM3RLkiRJjRm6JUmSpMYWDroASdJw2bR1jA2bt7Nz9zhLF4+wbs1K1q5aNuiyJGlOM3RLku6xaesY6zduY3zPXgDGdo+zfuM2AIO3JB0EQ7c0xzgKqZY2bN5+T+CeML5nLxs2b/fnTJIOgqFbmkMchVRrO3ePz6hdkjQ93kgpzSH7G4WUZsPSxSMzapckTY+hW5pDHIVUa+vWrGRk0YJ7tY0sWsC6NSsHVJEkzQ+GbmkOcRRSra1dtYzffc7jWLZ4hADLFo/wu895nNOXJOkgOadbmkPWrVl5rznd4CikZt/aVcsM2ZI0ywzd0hwyEYR8eokkSXOLoVuaYxyFlCRp7nFOtyRJktSYoVuSJElqzNAtSZIkNWboliRJkhozdEuSJEmNGbolSZKkxgzdkiRJUmOGbkmSJKkxQ7ckSZLUmKFbkiRJaszQLUmSJDVm6JYkSZIaM3RLkiRJjRm6JUmSpMYM3ZIkSVJjCwddgCRJOnRs2jrGhs3b2bl7nKWLR1i3ZiVrVy0bdFlSc4ZuSZJ0v9i0dYz1G7cxvmcvAGO7x1m/cRuAwVvzXtPpJUlOT7I9yfVJzp9i/XFJPplka5JrkpzRta9IMp7k6u71tq79wX1tVyf5epI/ankOkiRpdmzYvP2ewD1hfM9eNmzePqCKpPtPs5HuJAuAtwDPAHYAVyW5vKqu69vsdcBlVfXWJCcDVwArunU3VNUp/X1W1XeAe9qSbAE2tjoHSZI0e3buHp9RuzSftBzpPhW4vqpurKrvA+8Hzpy0TQFHdu+PAnZOt/MkJwEPAz4zC7VKkqTGli4emVG7NJ+0DN3LgFv6lnd0bf0uAM5JsoPeKPfL+tad0E07+VSSp0zR/1nAB6qqZrFmSZLUyLo1KxlZtOBebSOLFrBuzcoBVSTdfwb9yMCzgUuqajlwBvCeJIcBtwLHVdUq4JXApUmOnLTvWcD79tVxkhclGU0yumvXrkblS5Kk6Vq7ahm/+5zHsWzxCAGWLR7hd5/zOG+i1CGh5dNLxoBj+5aXd239zgNOB6iqK5McARxdVbcBd3btW5LcAJwEjAIkeTywsKq27OvgVXURcBHA6tWrHQ2XJGkIrF21zJCtQ1LLke6rgBOTnJDkcHoj05dP2uZm4DSAJI8GjgB2JVnS3YhJkkcAJwI39u13NvsZ5ZYkSZKGSbOR7qq6K8lLgc3AAuCdVXVtkguB0aq6HHgVcHGSV9C7qfLcqqokTwUuTLIHuBt4cVV9o6/759KbjiJJkiQNvRwK9yGuXr26RkdHB12GJEmS5rEkW6pq9VTrBn0jpSRJkjTvGbolSZKkxgzdkiRJUmMtHxkoTcumrWNs2LydnbvHWbp4hHVrVvo4KUmSNK8YujVQm7aOsX7jNsb37AVgbPc46zduAzB4S5KkecPpJRqoDZu33xO4J4zv2cuGzdsHVJEkSdLsM3RroHbuHp9RuyRJ0lxk6NZALV08MqN2SZKkucjQrYFat2YlI4sW3KttZNEC1q1ZOaCKJEnSXLVp6xhPfsMnOOH8j/DkN3yCTVvHBl3SPbyRUgM1cbOkTy+RJEkHY9gfzmDo1sCtXbVsKP4xSJKkuWt/D2cYhpzh9BJJkiTNecP+cAZDtyRJkua8YX84g6FbkiRJc96wP5zBOd2SJEma84b94QyGbkmSJM0Lw/xwBqeXSJIkSY0ZuiVJkqTGDN2SJElSY4ZuSZIkqTFDtyRJktSYoVuSJElqzNAtSZIkNWboliRJkhozdEuSJEmNGbolSZKkxgzdkiRJUmOGbkmSJKkxQ7ckSZLUmKFbkiRJaszQLUmSJDVm6JYkSZIaM3RLkiRJjRm6JUmSpMYM3ZIkSVJjhm5JkiSpMUO3JEmS1JihW5IkSWrM0C1JkiQ1tnDQBUiSJGlqm7aOsWHzdnbuHmfp4hHWrVnJ2lXLBl2W7gNDtyRJ0hDatHWM9Ru3Mb5nLwBju8dZv3EbgMF7DnJ6iSRJ0hDasHn7PYF7wvievWzYvH1AFelgGLolSZKG0M7d4zNq13AzdEuSJA2hpYtHZtSu4WboliRJGkLr1qxkZNGCe7WNLFrAujUrB1SRDoY3UkqSJA2hiZslfXrJ/GDoliRJGlJrVy0zZM8TTaeXJDk9yfYk1yc5f4r1xyX5ZJKtSa5JckbXviLJeJKru9fb+vY5PMlFSb6c5EtJfq7lOUiSJEkHq9lId5IFwFuAZwA7gKuSXF5V1/Vt9jrgsqp6a5KTgSuAFd26G6rqlCm6/k3gtqo6KclhwENanYMkSZI0G1pOLzkVuL6qbgRI8n7gTKA/dBdwZPf+KGDnNPr9JeCHAKrqbuDrs1WwJEmS1ELL6SXLgFv6lnd0bf0uAM5JsoPeKPfL+tad0E07+VSSpwAkWdyt++0kn0vywSTHtClfkiRJmh2DfmTg2cAlVbUcOAN4Tzdl5FbguKpaBbwSuDTJkfRG5pcDn62qJwBXAr8/VcdJXpRkNMnorl277o9zkSRJkqbUMnSPAcf2LS/v2vqdB1wGUFVXAkcAR1fVnVV1e9e+BbgBOAm4HfgesLHb/4PAE6Y6eFVdVFWrq2r1kiVLZueMJEmSpPugZei+CjgxyQlJDgfOAi6ftM3NwGkASR5NL3TvSrKkuxGTJI8ATgRurKoCPgw8rdv/NO49R1ySJEkaOunl2Ead9x4B+EfAAuCdVfU7SS4ERqvq8u6JJRcDD6J3U+Vrqupj3WMALwT2AHcDr6+qD3d9Hg+8B1gM7AJ+sapuPkAdu4Cbmpzk/h2NN3rOhNdrZrxeM+P1mjmv2cx4vWbG6zUzXq+ZGdT1Or6qppxi0TR0H+qSjFbV6kHXMVd4vWbG6zUzXq+Z85rNjNdrZrxeM+P1mplhvF6DvpFSkiRJmvcM3ZIkSVJjhu62Lhp0AXOM12tmvF4z4/WaOa/ZzHi9ZsbrNTNer5kZuuvlnG5JkiSpMUe6JUmSpMYM3Q0kOTbJJ5Ncl+TaJL8x6JqGWZIjkvxzks931+u3Bl3TXJBkQZKtSf560LUMuyRfTbItydVJRgddz7BLsjjJh5J8KckXk/zooGsaVklWdj9XE69vJ3n5oOsaZkle0f23/gtJ3pfkiEHXNMyS/EZ3ra71Z2tqSd6Z5LYkX+hre0iSv03yL92fPzjIGsHQ3cpdwKuq6mTgScCvdc8k19TuBH6yqh4PnAKcnuRJA65pLvgN4IuDLmIOeXpVnTJsj5AaUm8CPlpVPwQ8Hn/O9qmqtnc/V6cAT6T3rcl/OeCyhlaSZcCvA6ur6rH0vsfjrMFWNbySPBb4FeBUev8Wn5XkUYOtaihdApw+qe184ONVdSLw8W55oAzdDVTVrVX1ue79d+j9D2vZYKsaXtVzR7e4qHt5s8F+JFkO/Azw9kHXovklyVHAU4F3AFTV96tq92CrmjNOA26oqkF8GdtcshAYSbIQeACwc8D1DLNHA/9UVd+rqruATwHPGXBNQ6eqPg18Y1LzmcC7uvfvAtber0VNwdDdWJIVwCrgnwZbyXDrpkpcDdwG/G1Veb3274+A19D7xlYdWAEfS7IlyYsGXcyQO4Het/3+WTd96e1JHjjoouaIs4D3DbqIYVZVY8DvAzcDtwLfqqqPDbaqofYF4ClJHprkAcAZwLEDrmmuOKaqbu3e/ytwzCCLAUN3U0keBPwF8PKq+vag67qDpUUAAAQWSURBVBlmVbW3+3h2OXBq95GappDkWcBtVbVl0LXMIT9eVU8AnklvutdTB13QEFsIPAF4a1WtAr7LEHwsO+ySHA48G/jgoGsZZt282jPp/XK3FHhgknMGW9XwqqovAv8b+BjwUeBqYO9Ai5qDqveovoF/gm7obiTJInqB+71VtXHQ9cwV3cfYn+Tfz83Sv3ky8OwkXwXeD/xkkj8fbEnDrRtdo6puozff9tTBVjTUdgA7+j5t+hC9EK79eybwuar62qALGXI/BXylqnZV1R5gI/BjA65pqFXVO6rqiVX1VOCbwJcHXdMc8bUkDwfo/rxtwPUYultIEnrzIb9YVW8cdD3DLsmSJIu79yPAM4AvDbaq4VVV66tqeVWtoPdx9ieqypGifUjywCQPnngP/DS9j2w1har6V+CWJCu7ptOA6wZY0lxxNk4tmY6bgScleUD3/8rT8Ebd/UrysO7P4+jN5750sBXNGZcDv9C9/wXgrwZYC9D7GFGz78nAfwG2dfOUAV5bVVcMsKZh9nDgXUkW0PtF8LKq8jF4mi3HAH/Z+/87C4FLq+qjgy1p6L0MeG83ZeJG4BcHXM9Q636ZewbwXwddy7Crqn9K8iHgc/Se9LWVIfzmwCHzF0keCuwBfs0bm/+9JO8DngYcnWQH8HrgDcBlSc4DbgKeO7gKe/xGSkmSJKkxp5dIkiRJjRm6JUmSpMYM3ZIkSVJjhm5JkiSpMUO3JEmS1JihW5IkSWrM0C1Jh4Akz07S/Ovck1yS5Oe7929PcnL3/rWtjy1Jw8zndEuSZk2SS4C/rqoPTWq/o6oeNJiqJGnwHOmWpDkuyYokX+pGmb+c5L1JfirJPyT5lySnJjk3yZu77S9J8sdJPpvkxomR6X30/fAkn05ydZIvJHlK135Hkj9Mcm2SjydZMsW+/zfJ6iRvAEa6Pt7b7EJI0hAzdEvS/PAo4A+AH+pezwd+HHg1MNXUjod3659F7+uS9+X5wOaqOgV4PHB11/5AYLSqHgN8it7XLk+pqs4HxqvqlKp6wUxOSpLmi4WDLkCSNCu+UlXbAJJcC3y8qirJNmDFFNtvqqq7geuSHLOffq8C3plkUbfPROi+G/hA9/7PgY2zcRKSNF850i1J88Odfe/v7lu+m6kHWPq3z746rapPA08FxoBLkrxwX5tOv1RJOvQYuiVJ+5TkeOBrVXUx8HbgCd2qw4CJueDPB/7+AF3t6UbLJemQ5PQSSdL+PA1Yl2QPcAcwMdL9XeDUJK8DbgOed4B+LgKuSfI553VLOhT5yEBJ0oz5CEBJmhmnl0iSJEmNOdItSSLJ44D3TGq+s6p+ZBD1SNJ8Y+iWJEmSGnN6iSRJktSYoVuSJElqzNAtSZIkNWboliRJkhozdEuSJEmN/X+110lJgdx60QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6HqyLTkDaOO"
      },
      "source": [
        "Наивысший скор 0.8928 показала модель с параметрами ('gini', min_split=4, max_depth=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqX1Q_CU8-Xc"
      },
      "source": [
        "## Находим самые важные признаки (2 балла)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6gQmxxx8-Xd"
      },
      "source": [
        "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spdCq8it8-Xe"
      },
      "source": [
        "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший. \n",
        "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syu8KlvZ8-Xf"
      },
      "source": [
        "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUtzofWx8-Xg"
      },
      "source": [
        "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
        "Выведите 10 главных фичей по важности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "05ZVo-9P8-Xh"
      },
      "source": [
        "my_clf = MyDecisionTreeClassifier(criterion='gini', min_samples_split=4, max_depth=10)\n",
        "my_clf.fit(X_train, y_train)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlexa9bO8-Xi",
        "outputId": "044eb3a5-4f8a-40ed-c4e9-fe9b83bcd33f"
      },
      "source": [
        "feature_imp = my_clf.get_feature_importance()\n",
        "feature_imp = sorted(feature_imp.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "indices = [x[0] for x in feature_imp]\n",
        "values = [x[1] for x in feature_imp]\n",
        "names = X.columns[indices]\n",
        "\n",
        "print('Feature importances')\n",
        "for i, val in enumerate(values):\n",
        "    print(f\"{names[i]}: {val[0]}\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature importances\n",
            "like_o: 0.4431093270247809\n",
            "fun_o: 0.31999999999999984\n",
            "race: 0.31999999999999984\n",
            "imprelig: 0.3111111111111111\n",
            "income: 0.2895660203139429\n",
            "attr1_1_f: 0.17294117647058826\n",
            "goal_f: 0.1460336538461538\n",
            "mn_sat: 0.13265306122448983\n",
            "attr3_1: 0.10766491243635662\n",
            "shar2_1_f: 0.018882646691635696\n",
            "amb1_1_f: 0.017386939289790515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZZSw-VO8-Xj"
      },
      "source": [
        "## Фидбек (бесценно)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXg8fHOx8-Xk"
      },
      "source": [
        "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvEIbryp8-Xk"
      },
      "source": [
        "### Ваш ответ здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRNQpgpo8-Xl"
      },
      "source": [
        "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-1W4TMu8-Xt"
      },
      "source": [
        "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "pxirO5DS8-Xu"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}