{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCBp7jKUW_9Q"
   },
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №4 - Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQq3ZjzMW_9W"
   },
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 10 мая 2021, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 10 мая, -4 балла после 08:30 17 мая, -6 баллов после 08:30 24 мая, -8 баллов после 08:30 31 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0221, Задание 4] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjjcivKHW_9X"
   },
   "source": [
    "##  Считаем производные для функций потерь (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW8zMdvmW_9Y"
   },
   "source": [
    "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
    "\n",
    "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
    "\n",
    "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
    "\n",
    "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EjCvrj8W_9Y"
   },
   "source": [
    "1) $$-\\frac{dL}{da} = 2 (y_i-a(x_i))^2$$ \\\n",
    "2) $$-\\frac{dL}{da} = y_i exp(-a(x_i)y_i)$$ \\\n",
    "3) $$-\\frac{dL}{da} = \\frac{y_i exp(-a(x_i)y_i)}{1 + exp(-a(x_i)y_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAIaZkC2W_9Z"
   },
   "source": [
    "##  Реализуем градиентный бустинг (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ShmxtmWW_9Z"
   },
   "source": [
    "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlFKJnBLW_9a"
   },
   "source": [
    "Детали реализации:\n",
    "\n",
    "-- должно поддерживаться 3 функции потерь\n",
    "\n",
    "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
    "\n",
    "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
    "\n",
    "-- шаг в бустинге можно не подбирать, можно брать константный\n",
    "\n",
    "-- можно брать разные модели в качестве инициализации бустинга\n",
    "\n",
    "-- должны поддерживаться следующие параметры:\n",
    "\n",
    "а) число итераций \\\n",
    "б) размер шага \\\n",
    "в) процент случайных фичей при построении одного дерева \\\n",
    "д) процент случайных объектов при построении одного дерева \\\n",
    "е) параметры базового алгоритма (передавайте через **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ETV3fEDxW_9b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "H6W0z-sIW_9c"
   },
   "outputs": [],
   "source": [
    "class MyGradientBoostingClassifier:\n",
    "\n",
    "    def __init__(self, loss='MSE', learning_rate=0.01, n_estimators=100, \n",
    "                 colsample=1.0, subsample=1.0, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        loss -- один из 3 лоссов:\n",
    "        learning_rate -- шаг бустинга\n",
    "        n_estimators -- число итераций\n",
    "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
    "        colsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
    "        args, kwargs -- параметры  базовых моделей\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        self.params = args\n",
    "        self.kwparams = kwargs\n",
    "        self.models = []\n",
    "        self.features = []\n",
    "        if loss == 'MSE':\n",
    "            self.__loss = lambda true, pred: (true - pred) ** 2\n",
    "            self.__grad = lambda true, pred: 2 * (true - pred)\n",
    "        elif loss == 'exp':\n",
    "            self.__loss = lambda true, pred: np.exp(-true * pred)\n",
    "            self.__grad = lambda true, pred: true * np.exp(-true * pred)\n",
    "        elif loss == 'log':\n",
    "            self.__loss = lambda true, pred: np.log(1 + np.exp(-pred * true))\n",
    "            self.__grad = lambda true, pred: true * np.exp(-true * pred) /\\\n",
    "                                             (1 + np.exp(-pred * true))\n",
    "    \n",
    "    def fit(self, X, y, base_model=DecisionTreeRegressor, init_model=None):\n",
    "        \"\"\"\n",
    "        X -- объекты для обучения:\n",
    "        y -- таргеты для обучения\n",
    "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
    "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        if init_model is None:\n",
    "            self.init_model = None\n",
    "            pred = np.ones(X.shape[0]) / X.shape[0]\n",
    "        else:\n",
    "            model = init_model()\n",
    "            model.fit(X, y)\n",
    "            self.init_model = model\n",
    "            pred = model.predict(X)\n",
    "            pred = pred.astype(float)\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            features_num = int(self.colsample * X.shape[1])\n",
    "            features = np.random.randint(0, X.shape[1], size=features_num)\n",
    "            objects_num = int(self.subsample * X.shape[0])\n",
    "            objects = np.random.randint(0, X.shape[0], size=objects_num)\n",
    "\n",
    "            model = base_model(*self.params, **self.kwparams)\n",
    "            X_iter = X[objects]\n",
    "            model.fit(X_iter[:, features], self.__grad(y[objects], pred[objects]))\n",
    "\n",
    "            pred += self.learning_rate * model.predict(X[:, features])\n",
    "            self.models.append(model)\n",
    "            self.features.append(features)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Ваш код здесь\n",
    "        if self.init_model is None:\n",
    "            pred = np.ones(X.shape[0]) / X.shape[0]\n",
    "        else:\n",
    "            pred = self.init_model.predict(X).astype(float)\n",
    "            \n",
    "        for i in range(len(self.models)):\n",
    "            pred += self.learning_rate * self.models[i].predict(X[:, self.features[i]])\n",
    "        return np.round(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4ZbqWdJeW_9d"
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, \n",
    "                                                    stratify=wine.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "239DnunKW_9e",
    "outputId": "533b1128-728d-4e0f-b37b-36d61fd412ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "my_clf = MyGradientBoostingClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)\n",
    "\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5j-SfSZzW_9g"
   },
   "source": [
    "## Подбираем параметры (2 балла)\n",
    "\n",
    "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fc0THzhW_9g"
   },
   "source": [
    "В задании нужно\n",
    "\n",
    "1) Построить график точности в зависимости от числа итераций на валидации.\n",
    "\n",
    "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OE2nqDmgW_9h"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "im-dQANSW_9h",
    "outputId": "775be450-9943-4d37-bf26-60a7205b2c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "# Превращаем регрессию в классификацию\n",
    "y = (y > 2.0).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t20qOB6Zqik"
   },
   "source": [
    "Будем искать оптимальные параметры на валидации отдельно друг от друга, поскольку полный перебор занимает много времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V2N9OKtxYrK-"
   },
   "outputs": [],
   "source": [
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2ZhOfAiW_9h",
    "outputId": "416927a9-4fae-40e8-88a4-9c05d4b7210c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5780523255813953\n",
      "0.7267926356589148\n",
      "0.8651162790697674\n",
      "0.8865310077519379\n",
      "0.8900193798449613\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "grid = np.arange(10, 150, 30)\n",
    "for n_estimators in grid:\n",
    "    est_score = []\n",
    "    for train, val in KFold(n_splits=3, shuffle=True).split(X, y):\n",
    "        my_clf = MyGradientBoostingClassifier(n_estimators=n_estimators)\n",
    "        my_clf.fit(X[train], y[train])\n",
    "        est_score.append(accuracy_score(y[val], my_clf.predict(X[val])))\n",
    "    print(np.mean(est_score))\n",
    "    score.append(np.mean(est_score))\n",
    "\n",
    "best_params['n_estimators'] = grid[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "g1KEgbAyW_9i",
    "outputId": "54b86b20-a272-4d15-bd40-9b621be1b069"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAFOCAYAAABNDzFLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xV9f3H8dcngySssMImMmQIgowIqHUvnNSNVVu1FdEq4qjW0Yq0WttqW7TO9mcdKIg4iqMVK7VaRyVhCsiKIGGGlbASMj6/P+4BLjFo0HtzMt7Px+M+cs+875ubC++cfM+55u6IiIiIiMh3lxB2ABERERGRukLlWkREREQkRlSuRURERERiROVaRERERCRGVK5FRERERGJE5VpEREREJEZUrkVEREREYkTlWkRqJDNzMzs47BxVYWZpZva6mRWY2Utxeow93w8ze9zMfhG17BozW2dm28yspZkdZWZLgunvxyNPbWZm883suLBziEjdpHItInFhZv80s3GVzB9uZmvNLCmMXHFyPtAGaOnuF8T7wdx9lLv/CsDMkoE/AKe4e2N33wiMA/4cTL8W7zzRzOxpM/t1dT7m16ksj7v3cff34vBYx5lZXqz3KyK1i8q1iMTLM8ClZmYV5l8GPO/upSFkqhIzSzzATQ4CFn+b5xSDXzLaAKnA/Ap55le+etzzyLek771I3aByLSLx8hrQEjh69wwzaw6cCTxrZoPN7GMz22Jma8zsz2bWoCo7NrPLzSzXzLaa2RdmdknUsqvMbGGwbIGZDQzmH2Jm7wWPN9/Mzo7a5mkze8zM3jKz7cDxZtbezF42s/zgMUbvJ8s9wC+Bi4JhGD82swQzu8vMVpjZejN71szSg/U7B0M8fmxmXwLT97PfnwXfl9VmdmWFZU+b2a/NrAewKJi9xcymm9kyoCvwepAnxczSzez/gv2tCrZNjPpefmhmfzSzjcDYYJsHzOzLYLjJ42aWFqx/nJnlmdnNwXNbY2ZXBMtGApcAtwaP/fp+npub2ahg6MoWM3ukkl/CKtvuyuC13Wxmb5vZQcF8C/KvN7NCM5tnZofuL4+ZLTezk4L7Y83sJTObEPzMzDOzHmZ2e7C/lWZ2SlSGK6J+vnLN7OpgfiPgH0D74LG2BT9DKWb2p+B1XB3cT6nwvbzNzNYCfzOzVmb2RvB92WRmH5iZ/q8WqU3cXTfddNMtLjfgL8Bfo6avBmYH9wcBQ4EkoDOwEBgTta4DB1eyz0ZAIdAzmG4H9AnuXwCsAg4HDDiYyFHcZGApcAfQADgB2Bq1j6eBAuAoIgcdGgI5REpzAyJlNRc4dT/PcywwIWr6yuDxugKNgVeA54JlnYPn9mzwXNIq2d8wYB1waLDOC9HfjyDvryvsLylq++XASVHTrwJPBPtqDXwKXB0suxwoBa4PXos04I/AVKAF0AR4HfhNsP5xwfrjgu/r6cAOoHnFbF/zc+HAG0AzIBPIB4Z9wzbDg+/pIUHOu4CPgmWnBq9Xs+B1PwRot7880d+f4LUrCvaRFLwuXwB3Bs/vKuCLqG3PALoFj3Ns8NwHRn1v8io81jjgk+D7ngF8BPyqwvfyt0BK8L3/DfB48NjJRH45tbDfy7rpplvVb/ptWETi6RngfDNLDaZ/GMzD3XPc/RN3L3X35UTK37FV3G85cKiZpbn7GnffPQTiJ8Dv3H2GRyx19xVESnxj4H533+Xu04mUu4uj9vl3d//Q3cuBvkCGu48L1s8l8ovCiCrmuwT4g7vnuvs24HZghO37Z/+x7r7d3XdWsv2FwN/c/TN3306kAH4rZtaGSAEeEzzeeiLlOfq5rHb3hz0yrKUIGAnc6O6b3H0rcF+F9UuAce5e4u5vAduAngcY7X533+LuXwL/Bvp/w/qjiBT8hUHO+4D+wdHrEiK/BPQiUkQXuvuaA8jygbu/Hez3JSIl+H53LwEmAZ3NrBmAu7/p7suCn6//ANOI+utMJS4h8r1a7+75wD1EhkbtVg7c7e7Fwc9CCZFfGA8Kvr8fuLsfwHMRkZCpXItI3Lj7f4ENwPfNrBswmMhRWII/vb9hkZMbC4mUpVZV2Od24CIiZWuNmb1pZr2CxZ2AZZVs1h5YGRTn3VYAHaKmV0bdP4jIn/e37L4ROerd5puf9Z7HW1HhsZIqbL+S/WtfYfmK/a1YBbuP3K+Jei5PEDmSWlmWDIIj91Hr/zOYv9tG33d8+Q4iv7wciLUHuP1BwPioTJuIHD3uEPyy9GfgEWC9mT1pZk0PIMu6qPs7gQ3uXhY1ze58ZnaamX0SDNnYQuQXl6/7ua3sZ6F91HS+uxdFTf+eyBH6acGwk58fwPMQkRpA5VpE4u1ZIkesLwXedvfdReYx4HOgu7s3JVJev3HcLUBwlPFkIkf4PidyVBkiJbFbJZusBjpVGLuaSWQIyZ7dRt1fSWQoQLOoWxN3P70q+YLHO6jCY5Wyb4n7uqORa4j8ohC9/be1EigGWkU9l6bu3mc/WTYQKZR9otZPd/eqlud4HWVdSWQoS/RrkubuHwG4+0PuPgjoDfQAfhbrPMFY6ZeBB4A27t4MeIu9P7eVPVZlPwuro6b32cbdt7r7ze7eFTgbuMnMTozRUxCRaqByLSLx9ixwEpGxq89EzW9CZOz0tuDI8zVV2ZmZtbHI5fwaESmN24j8aR3gr8AtZjYoOMnt4GDYwP+IHB291cySLXKN47OI/Mm/Mp8CW4MTzdLMLDE4Qe7wKj7nicCNZtbFzBoTOSr/olf9aiKTgcvNrLeZNQTuruJ2XxEMj5gGPGhmTS1ysmU3M6t0CE5wdP8vwB/NrDWAmXUws1Or+JDriIw1j7XHgdvNrE+QKd3MLgjuH25mQyxyWcLtRIa27P6ZiGWeBkTGRucDpWZ2GnBK1PJ1QEsLTl4NTATuMrMMM2tFZBz/hP09gJmdGfzcGpHzAMqinouI1AIq1yISV8F46o+InEw3NWrRLcAPiJxY+BfgxSruMgG4icjRv01ExmlfEzzWS8C9RIaebCVyxZIW7r6LSJk+jciR2UeBH7r75/vJXEbkqib9iZzctoFIcU+vbP1KPAU8B7wfbF9E5ITBKnH3fwB/InIlkaXs54oiB+CHRIrhAmAzMIXIUf/9uS143E+CITv/oupjqv8P6B0M34jZNbbd/VUiJ/5NCjJ9RuT1BGhK5GdoM5FhFxuJDK+IaZ5g/PloIr/8bCby8zs1avnnRMp0bvB47YFfA9nAXGAeMDOYtz/diXy/twEfA4+6+7+/S24RqV6m8yRERERERGJDR65FRERERGJE5VpERGoEi3xYzbZKbo+HnU1EpKo0LEREREREJEZ05FpEREREJEaSvnmV2qFVq1beuXPnsGOIiIiISB2Xk5Ozwd0zKlsW13JtZsOA8UAi8Fd3v7/C8oOIXLIqg8gltS5197xg2Y+Au4JVf+3u0dfH/YrOnTuTnZ0d42cgIiIiIrIvM9vvJ+fGbViImSUS+Sja04h8YtbFZta7wmoPAM+6ez9gHPCbYNsWRD40YQiRj0u+28yaxyuriIiIiEgsxHPM9WBgqbvnBh/gMAkYXmGd3uz9cIR/Ry0/FXjH3Te5+2bgHWBYHLOKiIiIiHxn8SzXHYCVUdN5wbxoc4Bzg/vnAE3MrGUVtxURERERqVHCvlrILcCxZjaLyEcYrwLKqrqxmY00s2wzy87Pz49XRhERERGRKolnuV4FdIqa7hjM28PdV7v7ue4+ALgzmLelKtsG6z7p7lnunpWRUekJmyIiIiIi1Sae5XoG0N3MuphZA2AEMDV6BTNrZWa7M9xO5MohAG8Dp5hZ8+BExlOCeSIiIiIiNVbcyrW7lwLXESnFC4HJ7j7fzMaZ2dnBascBi8xsMdAGuDfYdhPwKyIFfQYwLpgnIiIiIlJj1ZmPP8/KynJd51pERERE4s3Mctw9q7JlYZ/QKCIiIiJSZ9SZjz8XERERkdrB3Sl3KCkrp7TcKStzSsrLKS1zSqO/ljulZU5JWTll5U5Jhfl92jelfbO0sJ/OPlSuRURERGogd6es3CNFstwpLftq2SwtL6ekzIPiuXf53oIatV3UuqVlUdtVtm5Z9PqR5SXlkfv7PN7X7WP3dvvsY29JjoUHLziM8wZ1jMm+YkXlWkRERGqtygpoxbK5uxBGHw3dU06jCmFJhXX33I86Urq3OFY4mrr7/j77qFB2v1KMv3pEtiwOBfRAJCUYSYlGUkLC3q/BvOTEBBITjKSEvfeTg3VSkpOC9RL2/brPvKjtgvnR+9j3cSPLkxMsWCd47H32kUCnFjXrqDWoXIuIiEgMlJaVk7+tmNVbilhbUMSagp3kbytmV+m+RzR3F9C9xbOyI6XRxXjvEdLdR0P3HUIQXgFNTkggMSiEyYl7S2BSVCHcUxQTEkhNrlg295bHpMSv7mPPulH7iKyz/wKa9JV9JASFNNiuYjGOeqzEBMPMqv37WdeoXIuIiMjXKit38rcWs7pgJ2sLili9ZWdQoCMlek1BEeu3FlNWoeg2SEwgJWl34UsIytzeo6HfVEB3F8LkoMzu2UeFcrn3aOtXC+i++4hed+8+Kh6FTVQBle9A5VpERKQe212cd5fkNQVFrNmykzWFka9rC4pYV0lxTk1OoH16Gm3TUzmyWyvapafSrllq5Gt6Gu3SU0lPS1YRlXpH5VpERKSOKit3Nmwr3luYo440rymIDN9YV1j0laEVKUkJtG+WRtumqQzt1nKfwtwuPY32zVScRfZH5VpERKQWKo8uztFHnaOK9P6K8+6SPKRLC9o1S6Vtehrt01Npm55K+/Q0mjVUcRb5tlSuRUREapjycmfD9mLWbNk7rnltQRGrC4pYW7CT1VsqL84N9hTnVAZ3abHnfrv0tGDIRhrNVZxF4krlWkREpBqVlzsbt+/ae7R5z/jmoqBA72RdYdFXLsO2uzi3bRopzpGjzJGjzrtLdItGDVScRUKmci0iIhIj5eXOph27WLOlaO+VNYKva7YUsaZwJ+sKitlVVr7Pdg0SE2gbDMvIOqh5ZJhGs0iRbt8sTcVZpBZRuRYREakC98gR5z2XoissCq7pvDMYrhG5VSzOyYlG22BoxsDM5lEnBu4drtGiYQMSElScReoClWsREan33J1N23dFnRS4s8IVNopYW1jErtKvFuc2TSMnAfbv1Ix2fVNp1zSVds3S9lymrmUjFWeR+kTlWkRE6jR3Z/OOkqgPPtn51RJdsP/i3C49NVKcg6PNe4ZspKfSqlGKirOI7EPlWkREai13Z8uOkqjxzXs/+GTPWOeCIoorFOekhL3FuV/HZpzaJ3XfoRrpqbRqrOIsIgdO5VpERGqk3cV53yPMu4drRIZprCnYSVHJvsU5McFoGxTnQzukc0qftsGJgXuv59yycQqJKs4iEgcq1yIiUu3cnYKdJV8pzBWLdGXFuU2TFNo1S6N3+6acdEjrPYW5XbO9R5xVnEUkLCrXIiISU+5O4c7Sr1yKbvWWItYW7txToneWlO2z3e7i3DY9ld7tm3Jir9Z7CvPu4RoZTVScRaRmU7kWEZEqc3cKi0r3HZ4RdSm63UV6x659i3OCQZumkZMAD2nXlON7ta7wyYGpZDROISkxIaRnJiISGyrXIiICRIrz1uLSfT4AJfpSdLsLdWXFuXWTVNo1S6VX2yYc33NvcW6bHhnrrOIsIvWFyrWISD2Vs2Izk2esZHXUNZ23VyjOZtC6SQrt0tPo0aYJx/YIinOzvUM1WjdRcRYR2U3lWkSkniktK+fP/17KQ+8uoUlqMp1bNaJ768Yc3b3Vng8+2X1ljdZNUkhWcRYRqTKVaxGReiRv8w7GTJpN9orNnDuwA/ec3YcmqclhxxIRqTNUrkVE6ok35q7m9lfm4Q7jR/RneP8OYUcSEalzVK5FROq47cWljJ06n5dy8hiQ2YzxFw0gs2XDsGOJiNRJKtciInXYvLwCRk+axfKN27n+hIMZfWJ3jaEWEYkjlWsRkTqovNz5ywe5PDBtEa0apzDxqqEM7doy7FgiInWeyrWISB2zvrCImybP4b9LN3DaoW35zbl9adawQdixRETqBZVrEZE65F8L1nHry3PZuauM+8/ty0WHd8JMHxcuIlJd4jrwzsyGmdkiM1tqZj+vZHmmmf3bzGaZ2VwzOz2Y39nMdprZ7OD2eDxziojUdkUlZfzy75/xk2ezads0ldev/x4jBmeqWIuIVLO4Hbk2s0TgEeBkIA+YYWZT3X1B1Gp3AZPd/TEz6w28BXQOli1z9/7xyiciUlcsWruV0RNnsWjdVn7yvS78bFhPUpISw44lIlIvxXNYyGBgqbvnApjZJGA4EF2uHWga3E8HVscxj4hIneLuPPfJCn795kKapibzzJWDObZHRtixRETqtXiW6w7AyqjpPGBIhXXGAtPM7HqgEXBS1LIuZjYLKATucvcP4phVRKRW2bR9F7dOmcO/Fq7n+J4Z/P6Cw2jVOCXsWCIi9V7YJzReDDzt7g+a2RHAc2Z2KLAGyHT3jWY2CHjNzPq4e2H0xmY2EhgJkJmZWd3ZRURC8d8lG7hp8my27Cjh7rN6c/mRnTW2WkSkhojnCY2rgE5R0x2DedF+DEwGcPePgVSglbsXu/vGYH4OsAzoUfEB3P1Jd89y96yMDP0pVETqtl2l5fzmrYVc+n//o2laMq/99CiuOKqLirWISA0SzyPXM4DuZtaFSKkeAfygwjpfAicCT5vZIUTKdb6ZZQCb3L3MzLoC3YHcOGYVEanRcvO3ccOk2cxbVcAlQzK564zepDXQSYsiIjVN3Mq1u5ea2XXA20Ai8JS7zzezcUC2u08Fbgb+YmY3Ejm58XJ3dzM7BhhnZiVAOTDK3TfFK6uISE3l7ryUk8fYqfNpkJTAE5cN4tQ+bcOOJSIi+2HuHnaGmMjKyvLs7OywY4iIxEzBzhLueHUeb85dw9CuLfjjRf1pl54WdiwRkXrPzHLcPauyZWGf0CgiIpWYsXwTYybNZl1hEbcO68nVx3QjMUFjq0VEajqVaxGRGqS0rJyHpy/l4elL6NSiIVOuOZL+nZqFHUtERKpI5VpEpIbI27yDMZNmk71iM+cO7MC44YfSOEX/TIuI1Cb6V1tEpAZ4fc5q7nh1HjiMH9Gf4f07hB1JRES+BZVrEZEQbS8u5e6p85mSk8eAzGY8NGIAnVo0DDuWiIh8SyrXIiIhmZu3hRsmzWbFxu2MPuFgrj+xO8mJ8fxsLxERiTeVaxGRalZe7jz5QS4PvL2IjCYpTLxqKEO6tgw7loiIxIDKtYhINVpXWMRNk2fz4dKNnHZoW+4/tx/pDZPDjiUiIjGici0iUk3+tWAdP5syh6KScu4/ty8XHd4JM127WkSkLlG5FhGJs6KSMu57ayHPfryC3u2a8tDFAzi4deOwY4mISByoXIuIxNHnawsZPXEWi9dt46qju3DLqT1JSUoMO5aIiMSJyrWISBy4O89+vIJ731pI09RknrlyMMf2yAg7loiIxJnKtYhIjG3cVsytU+by7ufrOb5nBr+/4DBaNU4JO5aIiFQDlWsRkRj675IN3DR5Nlt2lHD3Wb25/MjOOmlRRKQeUbkWEYmBXaXlPDhtEU+8n8vBrRvzzJWDOaRd07BjiYhINVO5FhH5jnLzt3HDpNnMW1XAJUMyueuM3qQ10EmLIiL1kcq1iMi35O68lJPH2KnzaZCUwBOXDeLUPm3DjiUiIiFSuRYR+RYKdpZwx6vzeHPuGo7o2pI/XtSftumpYccSEZGQqVyLiBygGcs3MWbSbNYVFnHrsJ5cfUw3EhN00qKIiKhci4hUWWlZOQ9PX8rD05fQqUVDplxzJP07NQs7loiI1CAq1yIiVbBy0w7GvDibnBWbOXdgB8YNP5TGKfonVERE9qX/GUREvsHrc1Zzx6vzwGH8iP4M798h7EgiIlJDqVyLiOzHtuJSxk6dz5ScPAZkNuOhEQPo1KJh2LFERKQGU7kWEanE3LwtjJ44iy837WD0CQcz+sTuJCUmhB1LRERqOJVrEZEo5eXOkx/k8sDbi2jdJIWJVw1lSNeWYccSEZFaQuVaRCSwrrCImybP5sOlGzm9b1t+c04/0hsmhx1LRERqEZVrERHgnQXruHXKHIpKyvnteX25MKsTZrp2tYiIHBiVaxGp14pKyrj3zYU898kK+rRvyvgRAzi4deOwY4mISC2lci0i9dbnawsZPXEWi9dt46qju3DLqT1JSUoMO5aIiNRiKtciUu+4O89+vIJ731pI09Rknr1yMMf0yAg7loiI1AEq1yJSr2zcVsytU+by7ufrOb5nBr+/4DBaNU4JO5aIiNQRcb1oq5kNM7NFZrbUzH5eyfJMM/u3mc0ys7lmdnrUstuD7RaZ2anxzCki9cMHS/IZNv4DPli6gbFn9eapyw9XsRYRkZiK25FrM0sEHgFOBvKAGWY21d0XRK12FzDZ3R8zs97AW0Dn4P4IoA/QHviXmfVw97J45RWRumtXaTkPTFvEk+/n0r11Y569cjCHtGsadiwREamD4jksZDCw1N1zAcxsEjAciC7XDuz+Hy4dWB3cHw5Mcvdi4AszWxrs7+M45hWROig3fxujJ83is1WFXDo0kztP701aA520KCIi8RHPct0BWBk1nQcMqbDOWGCamV0PNAJOitr2kwrbdohPTBGpi9ydl7LzuHvqfFKSE3jyskGc0qdt2LFERKSOC/uExouBp939QTM7AnjOzA6t6sZmNhIYCZCZmRmniCJS2xTsLOGOV+fx5tw1HNG1JX+8qD9t01PDjiUiIvVAPMv1KqBT1HTHYF60HwPDANz9YzNLBVpVcVvc/UngSYCsrCyPWXIRqbVmLN/EmEmzWVdYxK3DenL1Md1ITNAnLYqISPWI59VCZgDdzayLmTUgcoLi1ArrfAmcCGBmhwCpQH6w3ggzSzGzLkB34NM4ZhWRWq60rJw/vLOYi574mKREY8o1R3LtcQerWIuISLWK25Frdy81s+uAt4FE4Cl3n29m44Bsd58K3Az8xcxuJHJy4+Xu7sB8M5tM5OTHUuCnulKIiOzPyk07GPPibHJWbOa8gR25Z3gfGqeEPepNRETqI4t02dovKyvLs7Ozw44hItVs6pzV3PnKPAB+fc6hDO+vc59FRCS+zCzH3bMqW6ZDOyJSK20rLmXs1PlMycljYGYzxo8YQKcWDcOOJSIi9ZzKtYjUOnNWbuGGSbP4ctMORp9wMKNP7E5SYlw/cFZERKRKVK5FpNYoL3ee/CCXB95eROsmKUy8aihDurYMO5aIiMgeKtciUiusKyzixhdn89GyjZzety2/Oacf6Q2Tw44lIiKyD5VrEanx3lmwjlunzKGopJzfnteXC7M6YaZL7ImISM2jci0iNVZRSRn3vrmQ5z5ZQZ/2TXno4gF0y2gcdiwREZH9UrkWkRrp87WFjJ44i8XrtnHV0V245dSepCQlhh1LRETka6lci0iN4u48+/EK7n1rIU1Tk3n2ysEc0yMj7FgiIiJVonItIjXGxm3F/GzKXKZ/vp4TerXmd+f3o1XjlLBjiYiIVJnKtYjUCB8syeemyXMo2FnC2LN686MjO+ukRRERqXVUrkUkVLtKy3lg2iKefD+X7q0b8+yVgzmkXdOwY4mIiHwrKtciEprc/G2MnjSLz1YVcunQTO46ozepyTppUUREai+VaxGpdu7OS9l53D11PinJCTx52SBO6dM27FgiIiLfmcq1iFSrgh0l3PHqPN6ct4Yju7XkDxf2p216atixREREYkLlWkSqzadfbOLGF2ezrrCI24b1YuQxXUlM0EmLIiJSd6hci0jclZaV89D0pfx5+hIyWzTk5WuO5LBOzcKOJSIiEnMq1yISVys37WDMi7PJWbGZ8wZ25J7hfWicon96RESkbtL/cCISN1PnrObOV+YBMH5Ef4b37xByIhERkfhSuRaRmNtWXMrdf5/PyzPzGJjZjPEjBtCpRcOwY4mIiMSdyrWIxNSclVu4YdIsvty0g9Endmf0CQeTlJgQdiwREZFqoXItIjFRXu488X4uD05bROsmKUwaeQSDu7QIO5aIiEi1UrkWke9sbUERN02ezUfLNnJG33bcd05f0hsmhx1LRESk2qlci8h3Mm3+Wm57eS5FJeX87rx+XJDVETNdu1pEROonlWsR+VaKSsq4982FPPfJCg7t0JTxIwbQLaNx2LFERERCpXItIgds4ZpCRk+cxZL12xh5TFduPqUHKUmJYccSEREJncq1iFSZu/PMR8u57x+f0zQ1mWevHMwxPTLCjiUiIlJjqFyLSJVs3FbMz6bMZfrn6zmhV2t+d34/WjVOCTuWiIhIjaJyLSLf6P3F+dz80hwKdpZwz9l9+OERB+mkRRERkUqoXIvIfu0qLeeBaYt48v1curduzLNXDuaQdk3DjiUiIlJjqVyLSKWW5W/jhkmz+GxVIZcNPYg7zziE1GSdtCgiIvJ14lquzWwYMB5IBP7q7vdXWP5H4PhgsiHQ2t2bBcvKgHnBsi/d/ex4ZhWRCHdncvZKxk5dQEpyAk9eNohT+rQNO5aIiEitELdybWaJwCPAyUAeMMPMprr7gt3ruPuNUetfDwyI2sVOd+8fr3wi8lUFO0q449V5vDlvDUd2a8kfLuxP2/TUsGOJiIjUGvE8cj0YWOruuQBmNgkYDizYz/oXA3fHMY+IfI1Pv9jEmEmzWL+1mJ+f1ouRR3clIUEnLYqIiByIeJbrDsDKqOk8YEhlK5rZQUAXYHrU7FQzywZKgfvd/bV4BRWpz0rLynlo+lL+PH0JmS0a8vI1R3JYp2ZhxxIREamVasoJjSOAKe5eFjXvIHdfZWZdgelmNs/dl0VvZGYjgZEAmZmZ1ZdWpI5YuWkHN0yaxcwvt3D+oI6MPbsPjVNqyj8LIiIitU+V/xc1szQg090XVXGTVUCnqOmOwbzKjAB+Gj3D3VcFX3PN7D0i47GXVVjnSeBJgKysLK9iLhEB/j57FXe9+hkAD108gLMPax9yIhERkdovoSormdlZwGzgn8F0fzOb+g2bzQC6m1kXM2tApEB/ZRsz6wU0Bz6OmtfczFKC+62Ao9j/WG0ROQDbiku5efIcbpg0m3UvPFMAAB60SURBVB5tm/DWDUerWIuIiMRIVY9cjyVyguJ7AO4+28y6fN0G7l5qZtcBbxO5FN9T7j7fzMYB2e6+u2iPACa5e/SR50OAJ8ysnMgvAPdHX2VERL6dOSu3MHrSrMhwkBO7c/0JB5OUWKXfsUVERKQKqlquS9y9oMLHHX/jMAx3fwt4q8K8X1aYHlvJdh8BfauYTUS+QXm588T7uTw4bRGtm6QwaeQRDO7SIuxYIiIidU5Vy/V8M/sBkGhm3YHRwEfxiyUisbK2oIibJs/mo2UbOaNvO+47py/pDZPDjiUiIlInVbVcXw/cCRQDLxAZ6vHreIUSkdiYNn8tt748l+KScn53Xj8uyOpIhb9AiYiISAx9Y7kOPmnxTXc/nkjBFpEabueuMu59awETPvmSQzs0ZfyIAXTLaBx2LBERkTrvG8u1u5eZWbmZpbt7QXWEEpFvb+GaQkZPnMWS9du4+piu3HxKTxok6aRFERGR6lDVYSHbgHlm9g6wffdMdx8dl1QicsDcnWc+Ws59//ic9LRknvvxYI7unhF2LBERkXqlquX6leAmIjXQhm3F/OylOfx7UT4n9mrN787vR8vGKWHHEhERqXeqVK7d/Zngg2B6BLMWuXtJ/GKJSFW9vzifmybPobCohHvO7sMPjzhIJy2KiIiEpErl2syOA54BlgMGdDKzH7n7+/GLJiJfp7i0jAfeXsRfPviCHm0aM+Eng+nVtmnYsUREROq1qg4LeRA4xd0XAZhZD2AiMChewURk/5blb2P0xFnMX13IZUMP4s4zDiE1OTHsWCIiIvVeVct18u5iDeDui81Mn0IhUs3cncnZKxk7dQGpyQn85YdZnNy7TdixREREJFDVcp1tZn8FJgTTlwDZ8YkkIpUp2FHC7a/O5a15aznq4Jb84cL+tGmaGnYsERERiVLVcn0N8FMiH3sO8AHwaFwSichXfPrFJsZMmsX6rcX8/LRejDy6KwkJOmlRRESkpqlquU4Cxrv7H2DPpzbqOl8icVZaVs5D7y7hz/9eSmaLhrx8zZEc1qlZ2LFERERkP6part8FTiLyYTIAacA04Mh4hBIRWFdYxHUvzGTG8s2cP6gjY8/uQ+OUqr5lRUREJAxV/Z861d13F2vcfZuZNYxTJpF67+NlG7l+4ky2F5cxfkR/hvfvEHYkERERqYKqluvtZjbQ3WcCmFkWsDN+sUTqJ3fnyfdz+d3bizioZUNeuGooPdo0CTuWiIiIVFFVy/UNwEtmtjqYbgdcFJ9IIvVTYVEJt0yew7QF6zijbzt+e34/DQMRERGpZar6P3cXYACQCZwLDAE8XqFE6puFawq5ZkIOeZt38osze3PlUZ31EeYiIiK1UEIV1/uFuxcCzYDjiVyG77G4pRKpR16Zmcc5j37Ijl1lTBw5lB9/r4uKtYiISC1V1XJdFnw9A/iLu78JNIhPJJH6obi0jDtfncdNk+fQv1Mz3hj9PQ7v3CLsWCIiIvIdVHVYyCozewI4GfitmaVQ9WIuIhWs2rKTayfkMCevgFHHduOWU3qQlKi3lIiISG1X1XJ9ITAMeMDdt5hZO+Bn8YslUnf9Z3E+YybNorTMeeKyQZzap23YkURERCRGqlSu3X0H8ErU9BpgTbxCidRF5eXOw9OX8qd3F9OzTRMeu3QQXVo1CjuWiIiIxJCu8yVSDbbs2MWYF2fz3qJ8zh3QgXvP6Utag8SwY4mIiEiMqVyLxNm8vAJGTcghf2sxv/7+oVwyJFNXAxEREamjVK5F4sTdmTRjJXf/fT4ZTVKYPOoI+ndqFnYsERERiSOVa5E42LmrjF/8/TOm5ORxdPdWjB8xgBaNdPVKERGRuk7lWiTGVmzczqgJM1m4ppDRJ3bnhhO7k5igYSAiIiL1gcq1SAy9s2AdN02eTYIZf7v8cI7v1TrsSCIiIlKNVK5FYqC0rJw/vLOYR99bRt8O6Tx6yUA6tWgYdiwRERGpZirXIt/Rhm3FjJ44i4+WbeTiwZncfVZvUpN1mT0REZH6KK6ft2xmw8xskZktNbOfV7L8j2Y2O7gtNrMtUct+ZGZLgtuP4plT5NvKWbGJMx/6LzkrNvP78/vxm3P7qliLiIjUY3E7cm1micAjwMlAHjDDzKa6+4Ld67j7jVHrXw8MCO63AO4GsgAHcoJtN8crr8iBcHee/mg59765kA7N03jl2iPp0z497FgiIiISsngeuR4MLHX3XHffBUwChn/N+hcDE4P7pwLvuPumoFC/AwyLY1aRKtteXMroSbO55/UFHNezNVOv+56KtYiIiADxHXPdAVgZNZ0HDKlsRTM7COgCTP+abTvEIaPIAVm6fhujJuSQm7+NW4f1ZNQx3UjQZfZEREQkUFNOaBwBTHH3sgPZyMxGAiMBMjMz45FLZI835q7mtilzSU1OZMKPh3Dkwa3CjiQiIiI1TDyHhawCOkVNdwzmVWYEe4eEVHlbd3/S3bPcPSsjI+M7xhWpXElZOeNeX8B1L8yiZ9smvDn6aBVrERERqVQ8j1zPALqbWRcixXgE8IOKK5lZL6A58HHU7LeB+8yseTB9CnB7HLOKVGpdYRE/fX4m2Ss2c/mRnbnj9ENokBTXi+yIiIhILRa3cu3upWZ2HZGinAg85e7zzWwckO3uU4NVRwCT3N2jtt1kZr8iUtABxrn7pnhlFanMx8s2cv3EmezYVcZDFw/g7MPahx1JREREajiL6rS1WlZWlmdnZ4cdQ+oAd+eJ93P53T8/p0urRjx+6SC6t2kSdiwRERGpIcwsx92zKltWU05oFKkRCotKuGXyHKYtWMcZfdvx2/P70ThFbxMRERGpGrUGkcDCNYVcMyGHvM07+cWZvbnyqM6Y6TJ7IiIiUnUq1yLAKzPzuOPVeTRNTWbiyKEc3rlF2JFERESkFlK5lnqtuLSMca8v4Pn/fcnQri14+OKBZDRJCTuWiIiI1FIq11Jv5W3ewU+fn8mcvAJGHduNW07pQVKiLrMnIiIi357KtdRL/1mczw2TZlFW5jxx2SBO7dM27EgiIiJSB6hcS71SXu48PH0pf3p3MT3bNOGxSwfRpVWjsGOJiIhIHaFyLfXG5u27uHHybN5blM+5Azpw7zl9SWuQGHYsERERqUNUrqVemJu3hWsmzCR/azH3nnMoPxicqcvsiYiISMypXEud5u5M/HQlY6fOJ6NJCi+NOoLDOjULO5aIiIjUUSrXUmft3FXGL/7+GVNy8jimRwbjL+pP80YNwo4lIiIidZjKtdRJyzds55rnZ/L52kJuOLE7o0/sTmKChoGIiIhIfKlcS53zzoJ13DR5NokJxlOXH87xPVuHHUlERETqCZVrqTNKy8r5wzuLefS9ZfTtkM6jlwykU4uGYccSERGRekTlWuqEDduKGT1xFh8t28jFgzO5+6zepCbrMnsiIiJSvVSupdbLWbGJa5+fyZYdJfz+/H5ckNUp7EgiIiJST6lcS63l7jz90XLufXMhHZqn8eq1g+ndvmnYsURERKQeU7mWWml7cSm3vTyXN+au4aRD2vDghYeRnpYcdiwRERGp51SupdZZun4roybMJDd/G7cN68XVx3QlQZfZExERkRpA5VpqlTfmrua2KXNJa5DIhJ8M4churcKOJCIiIrKHyrXUCiVl5fzmrc956sMvGJjZjEcvGUTb9NSwY4mIiIjsQ+Vaary1BUVc98JMslds5oqjOnP7aYfQICkh7FgiIiIiX6FyLTXaR8s2MHriLHbsKuPhiwdw1mHtw44kIiIisl8q11IjuTtPvJ/L7/75OV1aNWLiVUPp3qZJ2LFEREREvpbKtdQ4hUUl3DJ5DtMWrOOMfu347Xn9aJyiH1URERGp+dRYpEZZuKaQaybkkLd5J788szdXHNUZM11mT0RERGoHlWupMV6Zmccdr84jPS2ZSSOHktW5RdiRRERERA6IyrWErri0jHGvL+D5/33J0K4tePjigWQ0SQk7loiIiMgBU7mWUOVt3sG1z89kbl4Bo47txi2n9CApUZfZExERkdpJ5VpC85/F+dwwaRZlZc4Tlw3i1D5tw44kIiIi8p2oXEu1Ky93Hpq+hPHvLqFnmyY8dukgurRqFHYsERERke8srn9/N7NhZrbIzJaa2c/3s86FZrbAzOab2QtR88vMbHZwmxrPnFJ9Nm/fxRVPz+BP/1rCOQM68Oq1R6lYi4iISJ0RtyPXZpYIPAKcDOQBM8xsqrsviFqnO3A7cJS7bzaz1lG72Onu/eOVT6rf3LwtXDNhJvlbi7nvnL5cPLiTLrMnIiIidUo8h4UMBpa6ey6AmU0ChgMLota5CnjE3TcDuPv6OOaRkLg7Ez9dydip88loksJLo47gsE7Nwo4lIiIiEnPxLNcdgJVR03nAkArr9AAwsw+BRGCsu/8zWJZqZtlAKXC/u78Wx6wSJzt3lXHXa5/x8sw8jumRwfiL+tO8UYOwY4mIiIjERdgnNCYB3YHjgI7A+2bW1923AAe5+yoz6wpMN7N57r4semMzGwmMBMjMzKze5PKNlm/YzqgJOSxat5UxJ3Xn+hO6k5igYSAiIiJSd8XzhMZVQKeo6Y7BvGh5wFR3L3H3L4DFRMo27r4q+JoLvAcMqPgA7v6ku2e5e1ZGRkbsn4F8a9Pmr+WsP/+XtYVF/O3ywxlzUg8VaxEREanz4lmuZwDdzayLmTUARgAVr/rxGpGj1phZKyLDRHLNrLmZpUTNP4p9x2pLDVVaVs5v//k5I5/LoXPLRrx+3fc4rmfrb95QREREpA6I27AQdy81s+uAt4mMp37K3eeb2Tgg292nBstOMbMFQBnwM3ffaGZHAk+YWTmRXwDuj77KiNRM+VuLGT1xFh/nbuQHQzL55Zm9SU1ODDuWiIiISLUxdw87Q0xkZWV5dnZ22DHqrZwVm7j2+Zls2VHCvef05fxBHcOOJCIiIhIXZpbj7lmVLQv7hEap5dydpz9azr1vLqRD8zRevXYwvds3DTuWiIiISChUruVb215cym0vz+WNuWs46ZA2PHjhYaSnJYcdS0RERCQ0KtfyrSxdv5VRE2aSm7+N24b14upjupKgq4GIiIhIPadyLQfsjbmruXXKXBo2SGTCT4ZwZLdWYUcSERERqRFUrqXKSsrKue+thfztw+UMOqg5j/xgIG3TU8OOJSIiIlJjqFxLlawtKOK6F2aSvWIzVx7VhdtP70VyYjwvky4iIiJS+6hcyzf6aNkGRk+cxY5dZTx88QDOOqx92JFEREREaiSVa9kvd+fx/+Ty+7c/p0urRkwaOZSDWzcJO5aIiIhIjaVyLZUqLCrh5slzeGfBOs7s1477z+tH4xT9uIiIiIh8HbUl+YqFawq5ZkIOeZt38ssze3PFUZ0x02X2RERERL6JyrXs4+WcPO58bR7paclMGjmUrM4two4kIiIiUmuoXAsAxaVl3PP6Al7435cc0bUlD108gIwmKWHHEhEREalVVK6FvM07uPb5mczNK2DUsd245ZQeJOkyeyIiIiIHTOW6nntv0XrGvDibsjLnicsGcWqftmFHEhEREam1VK7rqfJy56HpSxj/7hJ6tmnC45cOonOrRmHHEhEREanVVK7roc3bdzHmxdn8Z3E+5w7swL3f70tag8SwY4mIiIjUeirX9cyclVu49vmZ5G8t5r5z+nLx4E66zJ6IiIhIjKhc1xPuzsRPVzJ26nwymqQw5Zoj6NexWdixREREROoUlet6YOeuMu567TNenpnHsT0y+NNF/WneqEHYsURERETqHJXrOm75hu2MmpDDonVbGXNSd0af0J2EBA0DEREREYkHles6bNr8tdw8eQ6JicbfLj+c43q2DjuSiIiISJ2mcl0HlZaV8+A7i3nsvWX065jOo5cMpGPzhmHHEhEREanzVK7rmPytxYyeOIuPczfygyGZ3H1Wb1KSdJk9ERERkeqgcl2HZC/fxE9fmMmWHSU8cMFhnD+oY9iRREREROoVles6wN3524fLue+thXRonsar1w6md/umYccSERERqXdUrmu57cWl3PbyXN6Yu4aTe7fhgQsOIz0tOexYIiIiIvWSynUttnT9VkZNmElu/jZuG9aLq4/pqsvsiYiIiIRI5bqWemPuam6dMpeGDRKZ8JMhHNmtVdiRREREROo9letaZldpOb/5x0L+9uFyBh3UnEd+MJC26alhxxIRERERVK5rlbUFRfz0hZnkrNjMlUd14fbTe5GcmBB2LBEREREJxLWZmdkwM1tkZkvN7Of7WedCM1tgZvPN7IWo+T8ysyXB7UfxzFkbfLRsA2c+/AEL1xTy5x8M4Jdn9VaxFhEREalh4nbk2swSgUeAk4E8YIaZTXX3BVHrdAduB45y981m1jqY3wK4G8gCHMgJtt0cr7w1lbvz+H9y+f3bn9M1ozGTRg7k4NZNwo4lIiIiIpWI57CQwcBSd88FMLNJwHBgQdQ6VwGP7C7N7r4+mH8q8I67bwq2fQcYBkyMY94ap2BnCbe8NId3FqzjzH7t+O15/WiUopE8IiIiIjVVPJtaB2Bl1HQeMKTCOj0AzOxDIBEY6+7/3M+2HeIXteZZuKaQURNyWLV5J3ef1ZvLj+yMmS6zJyIiIlKThX0YNAnoDhwHdATeN7O+Vd3YzEYCIwEyMzPjkS8UL+fkcedr80hPS+bFq4cy6KAWYUcSERERkSqI5xlxq4BOUdMdg3nR8oCp7l7i7l8Ai4mU7apsi7s/6e5Z7p6VkZER0/BhKCop445X53HzS3MY0Kk5b44+WsVaREREpBaJZ7meAXQ3sy5m1gAYAUytsM5rRI5aY2atiAwTyQXeBk4xs+Zm1hw4JZhXZ63ctIMLn/iYF/73Jdcc143nfjyYVo1Two4lIiIiIgcgbsNC3L3UzK4jUooTgafcfb6ZjQOy3X0qe0v0AqAM+Jm7bwQws18RKegA43af3FgXvbdoPWNenE1ZufPkZYM4pU/bsCOJiIiIyLdg7h52hpjIysry7OzssGMckPJy56HpSxj/7hJ6tmnC45cOonOrRmHHEhEREZGvYWY57p5V2bKwT2istzZv38WYF2fzn8X5nDuwA/d+vy9pDRLDjiUiIiIi34HKdQjmrNzCtc/PJH9rMfed05eLB3fSZfZERERE6gCV62rk7rzw6ZfcM3UBGU1SmHLNEfTr2CzsWCIiIiISIyrX1WTnrjLufG0er8xcxbE9MvjTRf1p3qhB2LFEREREJIZUrqvB8g3bGTUhh0XrtnLjST24/oSDSUjQMBARERGRukblOs6mzV/LzZPnkJhoPH3FYI7tUfs/7EZEREREKqdyHSelZeU8MG0xj/9nGf06pvPoJQPp2Lxh2LFEREREJI5UruMgf2sxoyfO4uPcjVwyJJNfntWblCRdZk9ERESkrlO5jrHs5Zv46QszKdhZwoMXHMZ5gzqGHUlEREREqonKdYy4O3/7cDn3vbWQjs3TePqKwRzSrmnYsURERESkGqlcx8C24lJue3kub85dw8m92/DABYeRnpYcdiwRERERqWYq19/R0vVbGTVhJrn52/j5ab24+piu+rRFERERkXpK5fo7KCop45K//o+ycuf5nwzliG4tw44kIiIiIiFSuf4OUpMT+eOF/ema0Zi26alhxxERERGRkKlcf0dHHtwq7AgiIiIiUkMkhB1ARERERKSuULkWEREREYkRlWsRERERkRhRuRYRERERiRGVaxERERGRGFG5FhERERGJEZVrEREREZEYUbkWEREREYkRlWsRERERkRhRuRYRERERiRFz97AzxISZ5QMrws5RB7QCNoQdQvah16Rm0utS8+g1qXn0mtRMel2+u4PcPaOyBXWmXEtsmFm2u2eFnUP20mtSM+l1qXn0mtQ8ek1qJr0u8aVhISIiIiIiMaJyLSIiIiISIyrXUtGTYQeQr9BrUjPpdal59JrUPHpNaia9LnGkMdciIiIiIjGiI9ciIiIiIjGicl1PmVknM/u3mS0ws/lmdkMwv4WZvWNmS4KvzcPOWt+YWaKZzTKzN4LpLmb2PzNbamYvmlmDsDPWN2bWzMymmNnnZrbQzI7QeyVcZnZj8G/XZ2Y20cxS9V6pfmb2lJmtN7PPouZV+t6wiIeC12eumQ0ML3ndtp/X5ffBv2FzzexVM2sWtez24HVZZGanhpO67lC5rr9KgZvdvTcwFPipmfUGfg686+7dgXeDaaleNwALo6Z/C/zR3Q8GNgM/DiVV/TYe+Ke79wIOI/L66L0SEjPrAIwGstz9UCARGIHeK2F4GhhWYd7+3hunAd2D20jgsWrKWB89zVdfl3eAQ929H7AYuB0g+L9/BNAn2OZRM0usvqh1j8p1PeXua9x9ZnB/K5Gy0AEYDjwTrPYM8P1wEtZPZtYROAP4azBtwAnAlGAVvSbVzMzSgWOA/wNw913uvgW9V8KWBKSZWRLQEFiD3ivVzt3fBzZVmL2/98Zw4FmP+ARoZmbtqidp/VLZ6+Lu09y9NJj8BOgY3B8OTHL3Ynf/AlgKDK62sHWQyrVgZp2BAcD/gDbuviZYtBZoE1Ks+upPwK1AeTDdEtgS9Q9iHpFfgqT6dAHygb8Fw3X+amaN0HslNO6+CngA+JJIqS4ActB7pabY33ujA7Ayaj29RuG5EvhHcF+vS4ypXNdzZtYYeBkY4+6F0cs8cikZXU6mmpjZmcB6d88JO4vsIwkYCDzm7gOA7VQYAqL3SvUKxvAOJ/KLT3ugEV/9E7jUAHpv1DxmdieRoaHPh52lrlK5rsfMLJlIsX7e3V8JZq/b/We64Ov6sPLVQ0cBZ5vZcmASkT9xjyfyp9OkYJ2OwKpw4tVbeUCeu/8vmJ5CpGzrvRKek4Av3D3f3UuAV4i8f/ReqRn2995YBXSKWk+vUTUzs8uBM4FLfO+1mPW6xJjKdT0VjOX9P2Chu/8hatFU4EfB/R8Bf6/ubPWVu9/u7h3dvTORk0umu/slwL+B84PV9JpUM3dfC6w0s57BrBOBBei9EqYvgaFm1jD4t2z3a6L3Ss2wv/fGVOCHwVVDhgIFUcNHJM7MbBiRYYdnu/uOqEVTgRFmlmJmXYiccPppGBnrCn2ITD1lZt8DPgDmsXd87x1Exl1PBjKBFcCF7l7xZBWJMzM7DrjF3c80s65EjmS3AGYBl7p7cZj56hsz60/kJNMGQC5wBZGDE3qvhMTM7gEuIvLn7VnAT4iME9V7pRqZ2UTgOKAVsA64G3iNSt4bwS9CfyYyhGcHcIW7Z4eRu67bz+tyO5ACbAxW+8TdRwXr30lkHHYpkWGi/6i4T6k6lWsRERERkRjRsBARERERkRhRuRYRERERiRGVaxERERGRGFG5FhERERGJEZVrEREREZEYUbkWEREREYkRlWsRkTrKzPqb2elR02eb2c+/bpsD2PcYM2sYi32JiNQlus61iEgdFXzUcZa7XxeHfS8P9r3hALZJdPeyWGcREalJdORaRP6/vbsJsboK4zj+/aaFQVZUEAnBhARSCwMxqaAX2xRBi8iGoU0QgYsQihYuIsiNRbUoiqGiGqggjCCLQgSZXijsZXKukxUUCUVBuFB7w0DnaXHPwOUywQzeuDPw+6zOPefc8zz8V4eH5/5vDJk6on6rvqgeUveqZ//H3rXqHnVK/Vhd1+a3qF+rHfUj9SxgBzCqTquj6j3qs23/hDqu7ld/VG9UX255TPTEG1e/bHk92ua2AWuASXWyzY2pMy2Hx3u+/6f6lNoBrlEfU79RD6pP/j9PNCJieFK5jogYMnUE+IFuJXha3QW8U1WvzbN3H7C1qr5XNwE7q2qzOgPcUlW/qOdX1bH+ynXv53aBXgWMAbcDrwLXAYeAL4B7Wy4XtL+uXgHsA7ZV1cHeyrW6BtgPbACOAnuBZ6rqbbWA0arapV4IfAqsq6qay3PgDzQiYohSuY6IWBoOV9V0G08BI/0b1HOAa4E31WngeeCStvwJMKHeB6xYYMx3q1thmQF+q6qZqpqle8Gei3+X+hVwALgSuGKeczYCH1TVkao6CbwOXN/WTgFvtfFx4ATwknoH8PcC84yIWDZWDjuBiIgA4J+e8SlgvraQM4BjVXVV/0JVbW2V7NuAKXXDImLO9sWfBVaqlwEPARur6mhPtXsxTsz1WVfVSfVq4GbgTuB+YPMiz4uIWNJSuY6IWCaq6nfgsLoFwK71bby2qj6rqkeAI8ClwB/A6tMIeS7wF3BcvRi4tWet9+zPgRvUi1r7yBjwYf9hrfJ+XlW9DzwArD+N3CIilqRUriMilpe7gXH1YeBM4A2gAzyhXg5Itze6A/wEbG8tJDsXG6iqOuoB4DvgZ7qtJ3NeAPaov1bVTe0Vf5Mt/ntVtXueI1cDu9VVbd+Di80pImKpyw8aIyIiIiIGJG0hEREREREDkraQiIglSH2O7qvxej1dVa8MI5+IiFiYtIVERERERAxI2kIiIiIiIgYkl+uIiIiIiAHJ5ToiIiIiYkByuY6IiIiIGJBcriMiIiIiBuRf8CjCv3XzRrQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(grid, score)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('score')\n",
    "plt.title('Val score for different n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При дальнейшем увеличении количества n_estimators скор будет расти медленно и обучение будет происходить существенно дольше. Выберем оптимальный вариант между качеством и скоростью работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McZFPtkgW_9i",
    "outputId": "537614d3-5a0d-4c17-b374-3d30c1662a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8906492248062016\n",
      "0.8839147286821705\n",
      "0.7205910852713178\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "grid = ['MSE', 'exp', 'log']\n",
    "for loss in grid:\n",
    "    est_score = []\n",
    "    for train, val in KFold(n_splits=3, shuffle=True).split(X, y):\n",
    "        my_clf = MyGradientBoostingClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                              loss=loss)\n",
    "        my_clf.fit(X[train], y[train])\n",
    "        est_score.append(accuracy_score(y[val], my_clf.predict(X[val])))\n",
    "    print(np.mean(est_score))\n",
    "    score.append(np.mean(est_score))\n",
    "\n",
    "best_params['loss'] = grid[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKZBohUUW_9j",
    "outputId": "1dbff83d-230f-4fbd-f9af-4145ea61eed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855765503875969\n",
      "0.8890019379844961\n",
      "0.8772286821705427\n",
      "0.8669573643410852\n",
      "0.5255813953488372\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "grid = [0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "for lr in grid:\n",
    "    est_score = []\n",
    "    for train, val in KFold(n_splits=3, shuffle=True).split(X, y):\n",
    "        my_clf = MyGradientBoostingClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                              loss=best_params['loss'],\n",
    "                                              learning_rate=lr)\n",
    "        my_clf.fit(X[train], y[train])\n",
    "        est_score.append(accuracy_score(y[val], my_clf.predict(X[val])))\n",
    "    print(np.mean(est_score))\n",
    "    score.append(np.mean(est_score))\n",
    "\n",
    "best_params['learning_rate'] = grid[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GpPQ6-CW_9j",
    "outputId": "f2de4fa6-33fa-437a-f3dd-87127a9a0b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8896802325581395\n",
      "0.8905038759689923\n",
      "0.8749515503875968\n",
      "0.8238856589147288\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "grid = [1, 0.75, 0.5, 0.25]\n",
    "for cols in grid:\n",
    "    est_score = []\n",
    "    for train, val in KFold(n_splits=3, shuffle=True).split(X, y):\n",
    "        my_clf = MyGradientBoostingClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                              loss=best_params['loss'],\n",
    "                                              learning_rate=best_params['learning_rate'],\n",
    "                                              colsample=cols)\n",
    "        my_clf.fit(X[train], y[train])\n",
    "        est_score.append(accuracy_score(y[val], my_clf.predict(X[val])))\n",
    "    print(np.mean(est_score))\n",
    "    score.append(np.mean(est_score))\n",
    "\n",
    "best_params['colsample'] = grid[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZ1p6zsBbMmC",
    "outputId": "380ae039-db5b-4e49-f8e8-c7f83b055ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8900193798449613\n",
      "0.8898740310077519\n",
      "0.8903100775193798\n",
      "0.8861918604651162\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "grid = [1, 0.75, 0.5, 0.25]\n",
    "for subs in grid:\n",
    "    est_score = []\n",
    "    for train, val in KFold(n_splits=3, shuffle=True).split(X, y):\n",
    "        my_clf = MyGradientBoostingClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                              loss=best_params['loss'],\n",
    "                                              learning_rate=best_params['learning_rate'],\n",
    "                                              colsample=best_params['colsample'],\n",
    "                                              subsample=subs)\n",
    "        my_clf.fit(X[train], y[train])\n",
    "        est_score.append(accuracy_score(y[val], my_clf.predict(X[val])))\n",
    "    print(np.mean(est_score))\n",
    "    score.append(np.mean(est_score))\n",
    "\n",
    "best_params['subsample'] = grid[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BeHNAC2HcPx9",
    "outputId": "a80df85c-1d44-421f-b222-d4e7c3c963a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample': 0.75,\n",
       " 'learning_rate': 0.01,\n",
       " 'loss': 'MSE',\n",
       " 'n_estimators': 130,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrAF6c5BW_9j"
   },
   "source": [
    "## BooBag BagBoo (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53VPfcfCW_9j"
   },
   "source": [
    "Попробуем объединить бустинг и бэгинг. Давайте\n",
    "\n",
    "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
    "\n",
    "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSiRYczeW_9k"
   },
   "source": [
    "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "id": "gys0K1utW_9k"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DePlICVTW_9l",
    "outputId": "a1266f11-3627-4b43-8eae-5591952035fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8874354005167958"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "my_clf = MyGradientBoostingClassifier(**best_params)\n",
    "my_clf.fit(X_train, y_train, base_model=RandomForestRegressor)\n",
    "accuracy_score(y_test, my_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYDBjqUSdwcF",
    "outputId": "79527dfb-7026-40b6-a5fe-4f6d9f9c402f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8347868217054264"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "pred = np.zeros(y_test.shape)\n",
    "for i in range(N):\n",
    "    objects = np.random.randint(0, X_train.shape[0], size=X_train.shape[0] // N)\n",
    "    my_clf = MyGradientBoostingClassifier(**best_params)\n",
    "    my_clf.fit(X_train[objects], y_train[objects])\n",
    "    pred += my_clf.predict(X_test)\n",
    "accuracy_score(y_test, (pred / N)  >= 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rav2XrbVfDVH"
   },
   "source": [
    "Значительно улучшить качество с помощью первой модели (BooBag) не получилось. Хотя случайный лес хорошо подстраивается под выборку, но все равно скор примерно такой же, как и для классификатора с base_model=DecisionTreeClassifier. Получается, что обобщающая способность обычных деревьев не хуже, а в данном случае может и лучше, чем случайного леса. \n",
    "\n",
    "Вторая модель (BagBoo) показала скор хуже, чем один классификатор, так как каждую итерацию мы обучаем одну и ту же модель только на разных данных (возможно, ей недостаточно данных для того, чтобы подстроиться под всю выборку)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "31G41CtYW_9l"
   },
   "source": [
    "## Умная инициализация (1 балл)\n",
    "\n",
    "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
    "\n",
    "Получилось ли улучшить качество? Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "id": "W0yBg2fNW_9l"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxeC7r0jW_9l",
    "outputId": "2702eba2-2a43-4526-f9c7-a6bf7817de21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8968023255813954"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(**best_params)\n",
    "my_clf.fit(X_train, y_train, init_model=LinearRegression)\n",
    "accuracy_score(y_test, my_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgUv2Y0OfUn9",
    "outputId": "7f61bdd4-7c2f-406e-b632-357c544e783e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8864664082687338"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(**best_params)\n",
    "my_clf.fit(X_train, y_train, init_model=SGDClassifier)\n",
    "accuracy_score(y_test, my_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XUg3voDfUdV",
    "outputId": "47e68643-91ae-426c-9be0-d9058d29703d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8662790697674418"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(**best_params)\n",
    "my_clf.fit(X_train, y_train, init_model=LinearSVC)\n",
    "accuracy_score(y_test, my_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsqjHP5AfUUS",
    "outputId": "215517b1-b60e-4c82-e6cc-fa275244ed40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8229974160206718"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(**best_params)\n",
    "my_clf.fit(X_train, y_train, init_model=DecisionTreeClassifier)\n",
    "accuracy_score(y_test, my_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mM0_a4g7fUEu",
    "outputId": "20ee2b72-7102-45b0-9e12-70f1eef07390"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6356589147286822"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(**best_params)\n",
    "my_clf.fit(X_train, y_train, init_model=KNeighborsClassifier)\n",
    "accuracy_score(y_test, my_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skYTqTGXfntp"
   },
   "source": [
    "Получилось улучшить предикт в случае, если использовать LinearRegression. Остальные классификаторы не дали значимого прироста.\n",
    "\n",
    "Инициализирующая модель существенно влияет на качество предсказания, так как разные модели по-разному описывают данные. Если начать с предикта, который лучше всего подходит для наших данных, то можно быстро прийти к высокому скору на валидации (LinearRegression), и наоборот, плохое начальное предсказание может даже не привести к желаемому качеству модели (например, KNeighborsClassifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wxZTh0pW_9m"
   },
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AUPYrF6W_9m"
   },
   "source": [
    "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXeqp1etW_9m"
   },
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3MGdS_AW_9m"
   },
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5sosTZlW_9n"
   },
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "id": "Er-SBs_QW_9n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "hw4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
